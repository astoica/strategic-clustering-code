{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "10144c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This code implements the set of algorithms described in Section 5 from http://www.columbia.edu/~as5001/strategicclustering.pdf in order to find the next point in the fairness/utility-quality trade-off curve.'''\n",
    "import networkx as nx\n",
    "import csv \n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import math \n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import pickle\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d7b5b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function cluster_proportions() computes the proportions of different communities in each cluster; \n",
    "# the community affiliation of a node is embedded in a graph attribute called 'color' ('b' for majority, 'r' for minority); for using the real data, embed as such.\n",
    "def cluster_proportions(G, list_nodes_G, no_clusters, cluster_assignment):\n",
    "    # sizes of clusters                                                                                                    \n",
    "    unique, counts = np.unique(cluster_assignment, return_counts=True)\n",
    "    cluster_sizes = dict(zip(unique, counts))\n",
    "    # cluster_proportion is a dictionary mapping from the clusters to the proportion of the majority nodes in each cluster \n",
    "    cluster_proportion = {}\n",
    "    # cluster_majority is a dictionary mapping from the clusters to the number of the majority nodes in each cluster\n",
    "    cluster_majority = {}\n",
    "    # cluster_mminority is a dictionary mapping from the clusters to the number of the minority nodes in each cluster\n",
    "    cluster_minority = {}\n",
    "    for kk in range(no_clusters):\n",
    "        cluster_proportion[kk] = 0\n",
    "        cluster_majority[kk] = 0\n",
    "        cluster_minority[kk] = 0\n",
    "\n",
    "    for u in range(len(list_nodes_G)):\n",
    "        if G.nodes[list_nodes_G[u]]['color'] == 'b':\n",
    "            cluster_proportion[cluster_assignment[u]] += 1\n",
    "            cluster_majority[cluster_assignment[u]] += 1\n",
    "        else:\n",
    "            cluster_minority[cluster_assignment[u]] += 1\n",
    "\n",
    "    for kk in range(no_clusters):\n",
    "        cluster_proportion[kk] /= cluster_sizes[kk]\n",
    "    return cluster_sizes, cluster_proportion, cluster_majority, cluster_minority\n",
    "\n",
    "# the function graph_communities() finds the ratio of majority and minority nodes in the graph\n",
    "# the community affiliation of a node is embedded in a graph attribute called 'color' ('b' for majority, 'r' for minority); for using the real data, embed as such.\n",
    "def graph_communities(G, list_nodes_G):\n",
    "    maj_no = 0\n",
    "    min_no = 0\n",
    "    for u in range(len(list_nodes_G)):\n",
    "        if G.nodes[list_nodes_G[u]]['color'] == 'b':\n",
    "            maj_no += 1\n",
    "        else:\n",
    "            min_no += 1\n",
    "    return maj_no, min_no\n",
    "\n",
    "\n",
    "# the function compute_fairness_linear() computes a linear fairness metric defined as abs(#R in cluster - #B in cluster times (1-p)/p), where p = |B| / (|R| + |B|) in the general graph G\n",
    "def compute_fairness_linear(G, list_nodes_G, no_clusters, cluster_assignment):\n",
    "    fairness_clusters = {}\n",
    "    [cluster_sizes, cluster_proportion, cluster_majority, cluster_minority] = cluster_proportions(G,list_nodes_G, no_clusters, cluster_assignment)\n",
    "    [maj_no, min_no] = graph_communities(G, list_nodes_G)\n",
    "    maj_prop = maj_no / (maj_no + min_no)\n",
    "    for kk in range(no_clusters):\n",
    "        fairness_clusters[kk] = abs(cluster_minority[kk]- cluster_majority[kk]* (1 - maj_prop)/maj_prop)\n",
    " \n",
    "    fairness_overall = np.sum(list(fairness_clusters.values()))\n",
    "    return fairness_clusters, fairness_overall\n",
    "\n",
    "\n",
    "\n",
    "# the function compute_fairness_avgprop() computes the average fairness as defined by balance for a clustering as defined in http://proceedings.mlr.press/v97/kleindessner19b.html (avg balance)\n",
    "def compute_fairness_avgprop(G, list_nodes_G, no_clusters, cluster_assignment):\n",
    "    fairness_clusters = {}\n",
    "    [cluster_sizes, cluster_proportion, cluster_majority, cluster_minority] = cluster_proportions(G,list_nodes_G, no_clusters, cluster_assignment)\n",
    "    [maj_no, min_no] = graph_communities(G, list_nodes_G)\n",
    "    maj_prop = maj_no / (maj_no + min_no)\n",
    "    for kk in range(no_clusters):\n",
    "        fairness_clusters[kk] = abs(cluster_proportion[kk]- maj_prop)\n",
    " \n",
    "    fairness_overall = np.mean(list(fairness_clusters.values()))\n",
    "    return fairness_clusters, fairness_overall\n",
    "\n",
    "# computing the incluster degree of nodes, helper function for compute_fairness_avgprop_mfhg and compute_util_avgprop_closeness\n",
    "def incluster_degree(G, list_nodes_G, cluster_assignment, node):\n",
    "    degu = 0\n",
    "    for nbr in G.neighbors(node):\n",
    "        if cluster_assignment[list_nodes_G.index(node)] == cluster_assignment[list_nodes_G.index(nbr)]:\n",
    "            degu += 1\n",
    "    return degu\n",
    "\n",
    "\n",
    "# the function compute_fairness_avgprop_mfhg() computes the average utility as defined by mfu (https://www.semanticscholar.org/paper/Price-of-Pareto-Optimality-in-Hedonic-Games-Elkind-Fanelli/7764a4ee7d8e0a56c05439a429678d031ce601d4) \n",
    "# this utility function is mfu, from Price of Pareto Optimality in hedonic games by elkind et al, namely, w_i(C) / |C| - 1 (or w_i(C)/|C|) where w_i(C) is the sum of utility of node i in cluster C\n",
    "def compute_util_avgprop_mfhg(G, list_nodes_G, no_clusters, cluster_assignment):\n",
    "    util_clusters = {}\n",
    "    for i in range(no_clusters):\n",
    "        util_clusters[i] = 0\n",
    "        # indices in cluster i\n",
    "        cl = np.where(cluster_assignment == i)[0]\n",
    "        for j in cl: \n",
    "            deg_u = incluster_degree(G, list_nodes_G, cluster_assignment, list_nodes_G[j])\n",
    "            util_clusters[i] += deg_u/ (len(cl) - 1)\n",
    "    util_overall = np.mean(list(util_clusters.values()))\n",
    "    return util_clusters, util_overall\n",
    "\n",
    "# the function compute_util_avgprop_closeness() computes the average utility as defined by the closeness utility, section 3 in http://www.columbia.edu/~as5001/strategicclustering.pdf\n",
    "def compute_util_avgprop_closeness(G, list_nodes_G, no_clusters, cluster_assignment):\n",
    "    util_clusters = {}\n",
    "    for i in range(no_clusters):\n",
    "        util_clusters[i] = 0\n",
    "        # indices in cluster i\n",
    "        cl = np.where(cluster_assignment == i)[0]\n",
    "        for j in cl: \n",
    "            lengths_total = nx.single_source_shortest_path_length(G, list_nodes_G[j])\n",
    "            deg_u = incluster_degree(G, list_nodes_G, cluster_assignment, list_nodes_G[j])\n",
    "            lengths_j = 0\n",
    "            for jj in cl:\n",
    "                if j != jj:\n",
    "                    lengths_j += lengths_total[list_nodes_G[jj]]\n",
    "            util_clusters[i] += deg_u/lengths_j\n",
    "    util_overall = np.mean(list(util_clusters.values()))\n",
    "    return util_clusters, util_overall\n",
    "\n",
    "# the function compute_conductance() computes average conductance for a clustering assignment (a metric for 'quality' of clustering in networks)\n",
    "def compute_avg_conductance(G, list_nodes_G, no_clusters, cluster_assignment):\n",
    "    conductance = 0\n",
    "    conductance_clusters = {}\n",
    "    \n",
    "    for i in range(no_clusters):\n",
    "        ll = np.where(cluster_assignment==i)[0].tolist()\n",
    "        conductance_clusters[i] = nx.conductance(G, ll, list(set(list_nodes_G) - set(ll)))\n",
    "    conductance = np.mean(list(conductance_clusters.values()))\n",
    "    return conductance_clusters, conductance\n",
    "\n",
    "# the function compute_avg_kdistance_cl() computes the average distance to the k-means center obtained from the kmeans algorithm for a specified cluster\n",
    "# note: k-means doesn't optimize for average, this is just for our own experiments; in general, we use compute_avg_kdistance_cl_inertia defined below \n",
    "def compute_avg_kdistance_cl(cluster_assignment, my_cluster, km_distances):\n",
    "    avgdist = km_distances[np.where(cluster_assignment==my_cluster)][:,my_cluster].mean()\n",
    "    return avgdist\n",
    "\n",
    "# the function compute_avg_kdistance() computes the average distance of all clusters to their respective k-means centers obtained from the kmeans algorithm\n",
    "# note: k-means doesn't optimize for average, this is just for our own experiments; in general, we use compute_avg_kdistance_cl_inertia defined below \n",
    "def compute_avg_kdistance(cluster_assignment, no_clusters, km_distances):\n",
    "    dist_clusters = {}\n",
    "                                                                                                     \n",
    "    for kkk in range(no_clusters):\n",
    "        dist_clusters[kkk] = km_distances[np.where(cluster_assignment==kkk)][:,kkk].mean()\n",
    "    avgdist = np.mean(list(dist_clusters.values()))\n",
    "    return dist_clusters, avgdist\n",
    "\n",
    "# the function compute_avg_kdistance_cl() computes the average distance to the k-means center obtained from the kmeans algorithm for a specified cluster\n",
    "# note: this is what k-means optimizes for \n",
    "def compute_avg_kdistance_cl_inertia(cluster_assignment, my_cluster, km_distances):\n",
    "    sumdist = km_distances[np.where(cluster_assignment==my_cluster)][:,my_cluster].sum()\n",
    "    return sumdist\n",
    "\n",
    "# the function compute_avg_kdistance() computes the average distance of all clusters to their respective k-means centers obtained from the kmeans algorithm\n",
    "# note: this is what k-means optimizes for \n",
    "def compute_avg_kdistance_inertia(cluster_assignment, no_clusters, km_distances):\n",
    "    dist_clusters = {}\n",
    "                                                                                                     \n",
    "    for kkk in range(no_clusters):\n",
    "        dist_clusters[kkk] = (km_distances[np.where(cluster_assignment==kkk)][:,kkk]).sum()\n",
    "    sumdist = np.sum(list(dist_clusters.values()))\n",
    "    return dist_clusters, sumdist\n",
    "\n",
    "# # the function compute_avg_ncut() computes the normalized cut size between a subgraph S and a graph G\n",
    "def compute_avg_ncut(G, list_nodes_G, no_clusters, cluster_assignment):\n",
    "    ncut = 0\n",
    "    ncut_clusters = {}\n",
    "                                                                                                    \n",
    "    for i in range(no_clusters):\n",
    "        ll = np.where(cluster_assignment==i)[0].tolist()\n",
    "        ncut_clusters[i] = nx.normalized_cut_size(G, ll, list(set(list_nodes_G) - set(ll)))\n",
    "    ncut = np.mean(list(ncut_clusters.values()))\n",
    "    return ncut_clusters, ncut\n",
    "\n",
    "# the function doubly_weighted_G() creates a transformed doubly-weighted graph from an original inputted graph, where the weights represent the difference fairness/utility and quality, respectively.\n",
    "def doubly_weighted_G(G,Gnew, list_nodes_G,cluster_assignment,no_clusters, km_distances):\n",
    "    # use closeness utility\n",
    "    #[fairness_cl, fairness_all] = compute_util_avgprop_closeness(G, list_nodes_G, no_clusters, cluster_assignment)\n",
    "    # use statistical parity\n",
    "    [fairness_cl, fairness_all] = compute_fairness_linear(G, list_nodes_G, no_clusters, cluster_assignment)\n",
    "    [distances_cl, distances] = compute_avg_kdistance_inertia(cluster_assignment, no_clusters, km_distances)\n",
    "\n",
    "    for u in range(len(list_nodes_G)):\n",
    "        for v in range(len(list_nodes_G)):\n",
    "            if cluster_assignment[u] != cluster_assignment[v]:\n",
    "                cluster_assignment_copy = copy.deepcopy(cluster_assignment)\n",
    "                mycl = cluster_assignment[v]\n",
    "                # TODO: double check this, don't exchange them just compute the new clustering fairness/quality since you're changing the cluster assignment \n",
    "                cluster_assignment_copy[u], cluster_assignment_copy[v] = cluster_assignment[v], cluster_assignment[u]\n",
    "\n",
    "                # use closeness utility\n",
    "                #[fairness_cl_new, fairness_all_new] = compute_util_avgprop_closeness(G, list_nodes_G, no_clusters, cluster_assignment)\n",
    "                # use statistical parity\n",
    "                [fairness_cl_new, fairness_all_new] = compute_fairness_linear(G, list_nodes_G, no_clusters, cluster_assignment_copy)\n",
    "                distances_cl_new = compute_avg_kdistance_cl_inertia(cluster_assignment_copy, mycl, km_distances)\n",
    "\n",
    "                Gnew.add_edge(list_nodes_G[u],list_nodes_G[v],auv=(fairness_cl_new[mycl]-fairness_cl[mycl]),tuv=distances_cl_new-distances_cl[mycl])\n",
    "                #cluster_assignment[u], cluster_assignment[v] = cluster_assignment[v], cluster_assignment[u]\n",
    "    # adding edges from nodes to clusters\n",
    "    cluster_nodes = list(range(len(G.nodes()),len(G.nodes()) + no_clusters))\n",
    "    Gnew.add_nodes_from(cluster_nodes)\n",
    "    for u in range(len(list_nodes_G)):\n",
    "        for i in range(no_clusters):\n",
    "            if cluster_assignment[u] != i:\n",
    "                ucl = cluster_assignment[u]\n",
    "                cluster_assignment[u] = i\n",
    "                v = i + len(G.nodes())\n",
    "                # use closeness utility\n",
    "                #[fairness_cl_new, fairness_all_new] = compute_util_avgprop_closeness(G, list_nodes_G, no_clusters, cluster_assignment)\n",
    "                # use statistical parity\n",
    "                [fairness_cl_new, fairness_all_new] = compute_fairness_linear(G, list_nodes_G, no_clusters, cluster_assignment)\n",
    "                distances_cl_new = compute_avg_kdistance_cl_inertia(cluster_assignment, i, km_distances)               \n",
    "                Gnew.add_edge(list_nodes_G[u],v,auv=(fairness_cl_new[i]-fairness_cl[i]),tuv=distances_cl_new-distances_cl[i])\n",
    "                cluster_assignment[u] = ucl\n",
    "    # add node start \n",
    "    nn = len(Gnew.nodes())\n",
    "    Gnew.add_node(nn)\n",
    "\n",
    "    for j in cluster_nodes:\n",
    "        Gnew.add_edge(j,nn,auv=0,tuv=0)\n",
    "        Gnew.add_edge(nn,j,auv=0,tuv=0)\n",
    "\n",
    "    # TODO: REMOVE THIS: not necessary to have an edge from start to every node\n",
    "    # for j in range(len(G.nodes())):\n",
    "        # add an edge from start node to every node with weight equal to the difference if we remove the node from its cluster\n",
    "    #    mycl2 = cluster_assignment[j]\n",
    "    #    cluster_assignment[j] = (mycl2 + 1)%no_clusters\n",
    "        # use closeness utility\n",
    "        #[fairness_cl_new2, fairness_all_new2] = compute_util_avgprop_closeness(G, list_nodes_G, no_clusters, cluster_assignment)\n",
    "        # use statistical parity\n",
    "    #    [fairness_cl_new2, fairness_all_new2] = compute_fairness_linear(G, list_nodes_G, no_clusters, cluster_assignment)\n",
    "    #    distances_cl_new2 = compute_avg_kdistance_cl_inertia(cluster_assignment, mycl2, km_distances)\n",
    "    #    Gnew.add_edge(nn,list_nodes_G[j],auv=(fairness_cl_new2[mycl2]-fairness_cl[mycl2]),tuv=distances_cl_new2-distances_cl[mycl2])\n",
    "    #    cluster_assignment[j] = mycl2\n",
    "    #for j in range(len(G.nodes()),nn):\n",
    "    #    Gnew.add_edge(j,nn,auv=0,tuv=0)\n",
    "    \n",
    "    return Gnew\n",
    "\n",
    "# this is the classic Floyd-Warshall algorithm for finding whether there is a negative cycle in t_uv weights\n",
    "def negCyclefloydWarshall(G,list_nodes_G): \n",
    "    V = len(G.nodes())\n",
    "    # dist[][] will be the \n",
    "    # output matrix that will  \n",
    "    # finally have the shortest  \n",
    "    # distances between every \n",
    "    # pair of vertices  \n",
    "    #dist=[[0 for i in range(V+1)]for j in range(V+1)] \n",
    "    dist=[[0 for i in range(V)]for j in range(V)] \n",
    "       \n",
    "    # Initialize the solution \n",
    "    # matrix same as input \n",
    "    # graph matrix. Or we can \n",
    "    # say the initial values  \n",
    "    # of shortest distances \n",
    "    # are based on shortest  \n",
    "    # paths considering no \n",
    "    # intermediate vertex.  \n",
    "    for i in range(V): \n",
    "        for j in range(V): \n",
    "            if [list_nodes_G[i],list_nodes_G[j]] in G.edges():\n",
    "                dist[i][j] = G[i][j]['tuv'] \n",
    "            else:\n",
    "                dist[i][j] = math.inf\n",
    "    ''' Add all vertices one \n",
    "        by one to the set of  \n",
    "        intermediate vertices. \n",
    "    ---> Before start of a iteration, \n",
    "         we have shortest \n",
    "        distances between all pairs \n",
    "        of vertices such  \n",
    "        that the shortest distances \n",
    "        consider only the \n",
    "        vertices in set {0, 1, 2, .. k-1} \n",
    "        as intermediate vertices. \n",
    "    ----> After the end of a iteration, \n",
    "          vertex no. k is  \n",
    "        added to the set of \n",
    "        intermediate vertices and  \n",
    "        the set becomes {0, 1, 2, .. k} '''\n",
    "    for k in range(V): \n",
    "      \n",
    "        # Pick all vertices  \n",
    "        # as source one by one \n",
    "        for i in range(V): \n",
    "                   \n",
    "            # Pick all vertices as \n",
    "            # destination for the \n",
    "            # above picked source \n",
    "            for j in range(V): \n",
    "          \n",
    "                # If vertex k is on \n",
    "                # the shortest path from \n",
    "                # i to j, then update \n",
    "                # the value of dist[i][j] \n",
    "                if ((dist[i][k] + dist[k][j]) < dist[i][j]): \n",
    "                        dist[i][j] = dist[i][k] + dist[k][j] \n",
    "   \n",
    "    # If distance of any \n",
    "    # vertex from itself \n",
    "    # becomes negative, then \n",
    "    # there is a negative \n",
    "    # weight cycle. \n",
    "    for i in range(V): \n",
    "        if (dist[i][i] < 0): \n",
    "            return True\n",
    "   \n",
    "    return False\n",
    "\n",
    "# the function create_M_graph() creates a transformed graph with weights a_uv * M - t_uv\n",
    "def create_M_graph(G,newG, theM):\n",
    "    myG_M = nx.DiGraph()\n",
    "    myG_M.add_nodes_from(G)\n",
    "    auv_var=nx.get_edge_attributes(newG,'auv')\n",
    "    tuv_var=nx.get_edge_attributes(newG,'tuv')\n",
    "    for e in newG.edges():\n",
    "        # note that it is auv + M * tuv, in order to make M positive\n",
    "        myG_M.add_edge(e[0],e[1],weight=auv_var[e]+theM*tuv_var[e])\n",
    "    return myG_M\n",
    "\n",
    "# the function SPFA() implements a faster version of the Floyd-Warshall algorithm for finding negative cycles, without early termination and with cycle termination\n",
    "def SPFA(G):\n",
    "    queue = []\n",
    "    for v in G.nodes():\n",
    "        length[v] = 0\n",
    "        dis[v] = 0\n",
    "        pre[v] = 0\n",
    "        queue.append(v)\n",
    "    while len(queue) > 0:\n",
    "        u = queue.pop(0)\n",
    "        for (u, v) in G.edges():\n",
    "            if dis[u] + G[u][v]['weight'] < dis[v]:\n",
    "                pre[v] = u\n",
    "                length[v] = length[u] + 1\n",
    "                if length[v] == len(G.nodes()):\n",
    "                    return v,pre,\"negative cycle detected\"\n",
    "                dis[v] = dis[u] + G[u][v]['weight']\n",
    "                if v not in queue:\n",
    "                    queue.append(v)\n",
    "    return \"no negative cycle detected\"\n",
    "\n",
    "# the function Trace() traces the negative cycle from the vertex given by SPFA\n",
    "def Trace(pre, v):\n",
    "    mys = []\n",
    "    while v not in mys:\n",
    "        mys.append(v)\n",
    "        v = pre[v]\n",
    "    cycle = [v]\n",
    "    while mys[len(mys)-1] != v:\n",
    "        cycle.append(mys.pop())\n",
    "    cycle.append(v)\n",
    "    return cycle\n",
    "\n",
    "# the function compute_slope() computes the slope of line in Euclidean space\n",
    "def compute_slope(x1, y1, x2, y2):\n",
    "    return (float)(y2-y1)/(x2-x1)\n",
    "\n",
    "# the function SPFA() implements a faster version of the Floyd-Warshall algorithm for finding negative cycles, without early termination and with cycle termination, used only for the t-weights\n",
    "def SPFA2(G):\n",
    "    queue = []\n",
    "    for v in G.nodes():\n",
    "        length[v] = 0\n",
    "        dis[v] = 0\n",
    "        pre[v] = 0\n",
    "        queue.append(v)\n",
    "    while len(queue) > 0:\n",
    "        u = queue.pop(0)\n",
    "        for (u, v) in G.edges():\n",
    "            if dis[u] + G[u][v]['tuv'] < dis[v]:\n",
    "                pre[v] = u\n",
    "                length[v] = length[u] + 1\n",
    "                if length[v] == len(G.nodes()):\n",
    "                    return v,pre,\"negative cycle detected\"\n",
    "                dis[v] = dis[u] + G[u][v]['tuv']\n",
    "                if v not in queue:\n",
    "                    queue.append(v)\n",
    "    return \"no negative cycle detected\"\n",
    "\n",
    "# the function compute_conductance() computes average conductance for a clustering assignment\n",
    "def compute_conductance(G, list_of_nodes_G, cluster_assignment, no_of_clusters):\n",
    "    clconductance = {}\n",
    "    for i in range(no_of_clusters):\n",
    "        icl = [list_of_nodes_G[x] for x in list(np.where(cluster_assignment == i)[0])]\n",
    "        #print(icl)\n",
    "        if len(icl) == 0 or len(icl) == len(list_of_nodes_G):\n",
    "            clconductance[i] = 0\n",
    "        else:\n",
    "            clconductance[i] = nx.conductance(G,icl)\n",
    "    if(len([v for v in clconductance.values() if v > 0]) == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - sum(clconductance.values())/len([v for v in clconductance.values() if v > 0])\n",
    "\n",
    "# the function compute_balance is computing average balance of a graph and a clustering as defined by balance for a clustering as defined in http://proceedings.mlr.press/v97/kleindessner19b.html (avg balance)\n",
    "def compute_balance(G,list_of_nodes_G,cluster_assignment,no_of_clusters, sensitive_info):\n",
    "   balance_avg = 0\n",
    "   for cl in range(no_of_clusters):\n",
    "       \n",
    "       clind = np.where(cluster_assignment == cl)[0]\n",
    "       sens0cl = 0\n",
    "       sens1cl = 0\n",
    "       for j in clind:\n",
    "           if sensitive_info[j] == 0:\n",
    "               sens0cl += 1\n",
    "           else:\n",
    "               sens1cl +=1\n",
    "       if sens0cl == 0 or sens1cl == 0:\n",
    "           balance_cl = 0\n",
    "       else:\n",
    "           balance_cl = min(sens0cl/sens1cl,sens1cl/sens0cl)\n",
    "       balance_avg += balance_cl\n",
    "   return balance_avg/no_of_clusters\n",
    "\n",
    "# the function compute_balancemin is computing min balance of a graph and a clustering as defined by balance for a clustering as defined in http://proceedings.mlr.press/v97/kleindessner19b.html (avg balance)\n",
    "def compute_balancemin(G,list_of_nodes_G,cluster_assignment,no_of_clusters, sensitive_info):\n",
    "    balance_min = []\n",
    "    for cl in range(no_of_clusters):\n",
    "        clind = np.where(cluster_assignment == cl)[0]\n",
    "        sens0cl = 0\n",
    "        sens1cl = 0\n",
    "        for j in clind:\n",
    "            if sensitive_info[j] == 0:\n",
    "                sens0cl += 1\n",
    "            else:\n",
    "                sens1cl +=1\n",
    "        if sens0cl == 0 or sens1cl == 0:\n",
    "            balance_cl = 0\n",
    "        else:\n",
    "            balance_cl = min(sens0cl/sens1cl,sens1cl/sens0cl)\n",
    "        balance_min.append(balance_cl)\n",
    "    return min(balance_min)\n",
    "\n",
    "\n",
    "# this function is a Python-version of the Matlab code of the fair spectral clustering algorithm in http://proceedings.mlr.press/v97/kleindessner19b.html, used for comparing clustering with our own alg\n",
    "def Fair_SC_normalized(G, adj,no_clusters,sensitive):\n",
    "    n = np.shape(adj)[1]\n",
    "    sens_unique = np.unique(sensitive)    \n",
    "    h = len(sens_unique)\n",
    "    sensitiveNEW=sensitive.copy()\n",
    "    \n",
    "    temp = 0\n",
    "    \n",
    "    for ell in sens_unique:\n",
    "        sensitiveNEW[np.where(sensitive==ell)[0]] = temp\n",
    "        temp += 1\n",
    "\n",
    "    F=np.zeros([n,h-1])\n",
    "    for ell in range(h-1):\n",
    "        temp = np.where(sensitiveNEW == ell)[0]\n",
    "        F[temp,ell]=1\n",
    "        groupSize = len(temp)\n",
    "        F[:,ell] = F[:,ell]-groupSize/n\n",
    "\n",
    "    L = nx.normalized_laplacian_matrix(G)\n",
    "    L.todense()\n",
    "    D = np.diag(np.sum(np.array(adj.todense()), axis=1))\n",
    "\n",
    "    _,Z = null(F.transpose())\n",
    "    zz = ((Z.transpose()).dot(D)).dot(Z)\n",
    "    Q = scipy.linalg.sqrtm(zz)\n",
    "    Q = Q.real\n",
    "    Qinv = np.linalg.inv(Q)\n",
    "    \n",
    "    Msymm = ((((Qinv.transpose()).dot(Z.transpose())).dot(L.todense())).dot(Z)).dot(Qinv)\n",
    "    Msymm = (Msymm+Msymm.transpose())/2\n",
    "    e,v = np.linalg.eig(Msymm)\n",
    "    \n",
    "    i = [list(e).index(j) for j in sorted(list(e))[1:no_clusters]]\n",
    "    Y = np.array(v[:, i])\n",
    "    Y = Y.real\n",
    "\n",
    "    H = (Z.dot(Qinv)).dot(Y)\n",
    "    \n",
    "    km_fair = KMeans(init='k-means++', n_clusters=no_clusters, max_iter=200, n_init=200, verbose=0, random_state=3425)\n",
    "    km_fair.fit(H)\n",
    "    X_dist_fair = km_fair.transform(H)**2\n",
    "\n",
    "    clusterLabels = km_fair.labels_\n",
    "    return clusterLabels\n",
    "\n",
    "def null(a, rtol=1e-5):\n",
    "    u, s, v = np.linalg.svd(a)\n",
    "    rank = (s > rtol*s[0]).sum()\n",
    "    return rank, v[rank:].T.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e308b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # this code is an example for running a simulated model, generated by the stochastic block model \n",
    "# # main function to execute\n",
    "# if __name__ == \"__main__\":\n",
    "#     no_of_iterations = 30\n",
    "#     #iteration = 0\n",
    "#     fairness_list = []\n",
    "#     cost_list = []\n",
    "#     # this code includes the implementation of a stochastic block model; for reading the real data, please see / modify with the code from section5-nashequilibria-realdatasets.py\n",
    "#     # sizes of each block, the length of sizes defines the number of blocks\n",
    "#     sizes = [10, 10, 10, 10, 10]\n",
    "#     # probability of connections \n",
    "#     probs = [[0.7, 0.07, 0.05, 0.03, 0.05], \n",
    "#             [0.07, 0.6, 0.1, 0.05, 0.07], \n",
    "#             [0.05, 0.1, 0.5, 0.05, 0.1], \n",
    "#             [0.03, 0.05, 0.05, 0.6, 0.05], \n",
    "#             [0.05, 0.07, 0.1, 0.05, 0.6]]\n",
    "\n",
    "#     # create the graph based on the stochastic block model\n",
    "#     G_SBM = nx.stochastic_block_model(sizes, probs)\n",
    "\n",
    "#     nx.info(G_SBM)\n",
    "#     list_nodes=list(G_SBM.nodes())\n",
    "\n",
    "#     # add a label, red or blue, to each node, in a random fashion; 'ratio' is the ratio of the red nodes\n",
    "#     ratio = 0.3\n",
    "#     no_red = int(0.3*sum(sizes))\n",
    "#     no_blue = sum(sizes) - no_red\n",
    "#     attributes_r = ['r']*no_red\n",
    "#     attributes_b = ['b']*no_blue\n",
    "#     attributes = attributes_r + attributes_b\n",
    "#     random.shuffle(attributes)\n",
    "#     attributes_dict = {}\n",
    "#     count = 0\n",
    "#     for u in G_SBM.nodes():\n",
    "#         attributes_dict[u] = attributes[count]\n",
    "#         count += 1\n",
    "#     nx.set_node_attributes(G_SBM, attributes_dict,'color')\n",
    "\n",
    "#     # k is the number of clusters for spectral clustering\n",
    "#     k = len(sizes)\n",
    "#     # finding the spectrum of the graph\n",
    "#     A = nx.adjacency_matrix(G_SBM)\n",
    "#     L = nx.normalized_laplacian_matrix(G_SBM)\n",
    "#     L.todense()\n",
    "#     D = np.diag(np.sum(np.array(A.todense()), axis=1))\n",
    "\n",
    "#     e, v = np.linalg.eig(L.todense())\n",
    "\n",
    "#     i = [list(e).index(j) for j in sorted(list(e))[1:k]]\n",
    "#     print(i)\n",
    "\n",
    " \n",
    "#     U = np.array(v[:, i])\n",
    "#     # performing manual spectral clustering: using the first k values of the eigenspace to do k-means \n",
    "#     km = KMeans(init='k-means++', n_clusters=k, max_iter=200, n_init=200, verbose=0, random_state=3425)\n",
    "#     km.fit(U)\n",
    "#     y = km.labels_\n",
    "#     # distances from the k-centers\n",
    "#     X_dist = km.transform(U)**2\n",
    "\n",
    "#     # keeping a copy of the clustering assignment\n",
    "#     y_copy = copy.deepcopy(y)\n",
    "#     print(y_copy)\n",
    "\n",
    "    \n",
    "#     for iteration in range(no_of_iterations):\n",
    "#         print(\"Iteration number: \",iteration)\n",
    "#         # compute the cost and fairness of this clustering\n",
    "#         # using closeness utility\n",
    "#         [_,avgf] = compute_util_avgprop_closeness(G_SBM, list_nodes,k,y)\n",
    "#         # using statistical parity\n",
    "#         #[_,avgf] = compute_fairness_avgprop(G_SBM, list_nodes,k,y)\n",
    "#         print(\"Average unfairness: \", avgf)  \n",
    "        \n",
    "#         fairness_list.append(avgf)\n",
    "#         [_,avgcost] = compute_avg_kdistance(y,k,X_dist)\n",
    "#         print(\"Average cost: \", avgcost)\n",
    "#         cost_list.append(avgcost)\n",
    "#         if avgf == 0:\n",
    "#             break\n",
    "#         # generating G_new with double weights\n",
    "#         G_new = nx.DiGraph()\n",
    "#         G_new.add_nodes_from(G_SBM)\n",
    "#         G_new = doubly_weighted_G(G_SBM,G_new,list_nodes,y,k,X_dist)\n",
    "#         list_nodes_Gnew = list(G_new.nodes())\n",
    "\n",
    "#         length = {}\n",
    "#         dis = {}\n",
    "#         pre = {} \n",
    "#         result = SPFA2(G_new)\n",
    "#         # assert that G_new does not have a negative t-cycle\n",
    "#         if len(result) == 3:\n",
    "#             assert(iteration > 0)\n",
    "\n",
    "#             my_slope = compute_slope(fairness_list[iteration-1], cost_list[iteration-1], fairness_list[iteration], cost_list[iteration])\n",
    "#             myM = -1/my_slope\n",
    "#             epsilon = myM*1e-60\n",
    "#             print(\"M and slope:\", M, myM)\n",
    "#             for e in G_new.edges():\n",
    "#                 G_new[e[0]][e[1]]['tuv'] += G_new[e[0]][e[1]]['auv']/(myM+epsilon)\n",
    "#                 G_new[e[0]][e[1]]['tuv'] = round(G_new[e[0]][e[1]]['tuv'],10)\n",
    "\n",
    "#         length = {}\n",
    "#         dis = {}\n",
    "#         pre = {} \n",
    "#         newresult = SPFA2(G_new) \n",
    "\n",
    "#         if len(newresult) == 3:\n",
    "#             [vv,pre,stri] = newresult\n",
    "#             negt = Trace(pre,vv)\n",
    "#             print(negt)\n",
    "#             sumcycle = 0\n",
    "#             for i in range(len(negt) - 1):\n",
    "#                 sumcycle += G_new[negt[i]][negt[i+1]]['tuv']\n",
    "#             print(\"negative t-cycle was not fixed: \", sumcycle)\n",
    "#             y_neg = np.copy(y)\n",
    "#             for i in range(len(negt)):\n",
    "#                 if negt[i] < len(G_SBM.nodes()):\n",
    "#                     if i == len(negt) - 1:\n",
    "#                         break\n",
    "#                     if negt[i+1] < len(G_SBM.nodes()):\n",
    "#                         y_neg[negt[i]] = y[negt[i+1]]\n",
    "#                     if negt[i + 1] >= len(G_SBM.nodes()) and negt[i+1] < len(G_SBM.nodes()) + k:\n",
    "#                         y_neg[negt[i]] = negt[i+1] % len(G_SBM.nodes())\n",
    "#             _,avgdistneg = compute_avg_kdistance(y_neg, k, X_dist)\n",
    "#             # using closeness utility\n",
    "#             _,avgfairnessneg = compute_util_avgprop_closeness(G_SBM, list_nodes,k,y_neg)\n",
    "#             # using statistical parity\n",
    "#             #_,avgfairnessneg = compute_fairness_avgprop(G_SBM, list_nodes,k,y_neg)\n",
    "#             print(\"Cost when correcting a negative cycle: \", avgdistneg)\n",
    "#             print(\"Fairness when correcting a negative cycle: \", avgfairnessneg)\n",
    "\n",
    "#             break\n",
    "\n",
    "#         length = {}\n",
    "#         dis = {}\n",
    "#         pre = {} \n",
    "\n",
    "#         print(\"we're finding Mlow\")\n",
    "        \n",
    "#         Mfind = 1\n",
    "#         G_M = create_M_graph(G_SBM,G_new, Mfind)\n",
    "#         mresult = SPFA(G_M)\n",
    "#         if(len(mresult) != 3):\n",
    "#             Mfind = 0\n",
    "#             G_M = create_M_graph(G_SBM,G_new, Mfind)\n",
    "#             assert(len(SPFA(G_M)) == 3)\n",
    "#         else:\n",
    "#             while True:\n",
    "#                 G_M = create_M_graph(G_SBM,G_new, Mfind)\n",
    "#                 if SPFA(G_M) == 'no negative cycle detected':\n",
    "#                     break\n",
    "#                 Mfind *= 2\n",
    "\n",
    "#         #print(\"we found Mlow\")\n",
    "#         # initialize M and the limits for the binary search\n",
    "#         M = Mfind/2\n",
    "#         delta = Mfind/2\n",
    "#         low = Mfind/2\n",
    "#         high = Mfind\n",
    "\n",
    "#         # binary search to find M for which there is a cycle of length 0\n",
    "#         termination_condition = 10e-14\n",
    "#         mids = []\n",
    "#         while np.abs(delta) > termination_condition:\n",
    "#             if high > low: \n",
    "#                 mid = (high + low) / 2\n",
    "#                 mids.append(mid)\n",
    "#             G_M = create_M_graph(G_SBM,G_new, mid)\n",
    "#             if SPFA(G_M) == 'no negative cycle detected':\n",
    "#                 delta = mid - low\n",
    "#                 high = mid\n",
    "#             else:\n",
    "#                 delta = high - mid\n",
    "#                 low = mid\n",
    "#         whereinmidsweare = 0\n",
    "#         for mm in reversed(mids):\n",
    "#             whereinmidsweare += 1\n",
    "#             G_M = create_M_graph(G_SBM,G_new, mm)\n",
    "#             if len(SPFA(G_M)) == 3:\n",
    "#                break\n",
    "#         if whereinmidsweare == len(mids):\n",
    "#             break\n",
    "#         M=mm\n",
    "        \n",
    "#         G_M = create_M_graph(G_SBM,G_new, M)\n",
    "#         [v,pre,stri]=SPFA(G_M)\n",
    "#         myc = Trace(pre,v)\n",
    "#         print(\"best cycle: \",myc)\n",
    "#         ytest = np.copy(y)\n",
    "#         for i in range(len(myc)):\n",
    "#             print(myc[i])\n",
    "#             if myc[i] < len(G_SBM.nodes()):\n",
    "#                 if i == len(myc) - 1:\n",
    "#                     break\n",
    "#                 if myc[i+1] < len(G_SBM.nodes()):\n",
    "#                     #a = y[myc[i]]\n",
    "#                     ytest[myc[i]] = y[myc[i+1]]\n",
    "#                 if myc[i + 1] >= len(G_SBM.nodes()) and myc[i+1] < len(G_SBM.nodes()) + k:\n",
    "#                     print(myc[i+1])\n",
    "#                     ytest[myc[i]] = myc[i+1] % len(G_SBM.nodes())\n",
    "#         y = np.copy(ytest)\n",
    "\n",
    "#     print(\"Fairness: \", fairness_list)\n",
    "#     print(\"Cost: \", cost_list)\n",
    "#     filename = 'SBM_n' + str(len(list_nodes)) + '_r' + str(ratio) + '_k' + str(k) + 'closeness'\n",
    "#     f = open('filename','w')\n",
    "#     writer=csv.writer(f,lineterminator=\"\\n\")\n",
    "#     writer.writerow(fairness_list)\n",
    "#     writer.writerow(cost_list)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5fd1ad49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female:  76\n",
      "male:  51\n"
     ]
    }
   ],
   "source": [
    "### the following section reads in one of the datasets: APS, Facebook, Highschool; uncomment for the data desired to use\n",
    "'''#APS dataset: \n",
    "filename = 'APS-clusteringgames-utilities-conductance.csv'\n",
    "\n",
    "# read in the data as a graph\n",
    "G_og = nx.read_gexf('Downloads/clustering_plotting/APS/sampled_APS_pacs052030.gexf')\n",
    "\n",
    "# work with the largest connected compoenent\n",
    "gg = sorted(nx.connected_components(G_og),key=len,reverse=True)[0]\n",
    "Gc = G_og.subgraph(gg)\n",
    "\n",
    "list_nodes=list(Gc.nodes())\n",
    "\n",
    "\n",
    "# finding the spectrum of the graph\n",
    "A = nx.adjacency_matrix(Gc)\n",
    "L = nx.normalized_laplacian_matrix(Gc)\n",
    "L.todense()\n",
    "D = np.diag(np.sum(np.array(A.todense()), axis=1))\n",
    "e, v = np.linalg.eig(L.todense())\n",
    "'''\n",
    "\n",
    "'''#Facebook dataset: \n",
    "filename = 'Facebook-clusteringgames-utilities-conductance.csv'\n",
    "\n",
    "# read in the data as a graph\n",
    "Gc = nx.read_edgelist('Facebook/facebook_combined.txt')\n",
    "\n",
    "list_nodes=list(Gc.nodes())\n",
    "\n",
    "# finding the spectrum of the graph\n",
    "A = nx.adjacency_matrix(Gc)\n",
    "L = nx.normalized_laplacian_matrix(Gc)\n",
    "L.todense()\n",
    "D = np.diag(np.sum(np.array(A.todense()), axis=1))\n",
    "e, v = np.linalg.eig(L.todense())\n",
    "\n",
    "gender = {}\n",
    "egos = ['0', '107','348','414','686','698','1684','1912','3437','3980']\n",
    "genderfeatfinder = {}\n",
    "\n",
    "# find the sensitive feaures (anonymized gender), and place them in a dictionary\n",
    "for u in egos: \n",
    "    genderfeatfinder[u] = {}\n",
    "    filenamefeat = 'Facebook/' + u + '.featnames'\n",
    "    ffeat = open(filenamefeat)\n",
    "    readerfeat = csv.reader(ffeat)\n",
    "    for rowfeat in readerfeat:\n",
    "        myrowfeat = rowfeat[0].split()\n",
    "        genderfeatfinder[u][myrowfeat[0]] = myrowfeat[1].split(';')[0]\n",
    "    ffeat.close()\n",
    "    gender_ind = [k for k,v in genderfeatfinder[u].items() if v == 'gender']\n",
    "    filenameego= 'Facebook/' + u +'.egofeat'\n",
    "    fego = open(filenameego)\n",
    "    readerego =csv.reader(fego)\n",
    "    for rowego in readerego:\n",
    "        myrowego = rowego[0].split()\n",
    "        gender[u] = myrowego[int(max(gender_ind))]\n",
    "    fego.close()\n",
    "    filename= 'Facebook/' + u +'.feat'\n",
    "    f = open(filename)\n",
    "    reader =csv.reader(f)\n",
    "    for row in reader:\n",
    "        myrow = row[0].split()\n",
    "        user = myrow[0]\n",
    "        gender[user] = myrow[int(max(gender_ind))+1]\n",
    "    f.close()\n",
    "\n",
    "# create a list, sensitive[], that encodes the anonymized gender in the data; it is not used in this section\n",
    "sensitive = []\n",
    "for u in list_nodes:\n",
    "    if (gender[u] == '1'):\n",
    "        sensitive.append(1)\n",
    "    else:\n",
    "        sensitive.append(0)\n",
    "sensitive = np.array(sensitive)\n",
    "sensitive\n",
    "'''\n",
    "\n",
    "#Highschool dataset:\n",
    "filename = 'Highschool-clusteringgames-utilities-conductance.csv'\n",
    "\n",
    "# read in the data as a graph\n",
    "G_og = nx.read_edgelist('Friendship-network_data_2013.csv')\n",
    "\n",
    "# get the largest connected component of the graph\n",
    "gg = sorted(nx.connected_components(G_og),key=len,reverse=True)[0]\n",
    "Gbig = G_og.subgraph(gg)\n",
    "G_SBM = Gbig.copy()\n",
    "\n",
    "# find the sensitive features (unanonymized gender) and place it in a dictionary\n",
    "gender = {}\n",
    "\n",
    "filename_read = 'metadata_2013.txt'\n",
    "f = open(filename_read)\n",
    "reader=csv.reader(f)\n",
    "\n",
    "for row in reader:\n",
    "    myrow = row[0].split('\\t')\n",
    "    gender[myrow[0]] = myrow[2]\n",
    "\n",
    "list_init = list(G_SBM.nodes())\n",
    "for u in list_init:\n",
    "    if gender[u] == 'Unknown':\n",
    "        G_SBM.remove_node(u)\n",
    "        \n",
    "# find the spectrum of the graph\n",
    "list_nodes = list(G_SBM.nodes())\n",
    "\n",
    "m = 0 \n",
    "f = 0\n",
    "d = {} \n",
    "for u in G_SBM.nodes():\n",
    "    if gender[u] == 'M':\n",
    "        d[u] = 'b'\n",
    "        m += 1\n",
    "    elif gender[u] == 'F':\n",
    "        d[u] = 'r'\n",
    "        f += 1\n",
    "print('female: ', f)\n",
    "print('male: ', m)\n",
    "\n",
    "nx.set_node_attributes(G_SBM, d, name=\"color\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "55b18611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code puts the sensitive attributes in a matrix; this is useful for comparing with the fair spectral clustering algorithm from http://proceedings.mlr.press/v97/kleindessner19b.html\n",
    "sensitive = []\n",
    "for u in list_nodes:\n",
    "    if gender[u] == 'F':\n",
    "        sensitive.append(1)\n",
    "    else:\n",
    "        sensitive.append(0)\n",
    "sensitive = np.array(sensitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f29c088d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Graph with 127 nodes and 396 edges'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G_SBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "441e16ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 1 1\n",
      " 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1]\n",
      "Iteration number:  0\n",
      "Average unfairness:  32.470588235294116\n",
      "Average cost:  1.1903907713067448\n",
      "we're finding Mlow\n",
      "256.0\n",
      "128.0\n",
      "64.0\n",
      "32.0\n",
      "16.0\n",
      "8.0\n",
      "4.0\n",
      "2.0\n",
      "1.0\n",
      "0.5\n",
      "0.25\n",
      "0.125\n",
      "0.0625\n",
      "0.03125\n",
      "0.015625\n",
      "0.0078125\n",
      "0.00390625\n",
      "0.001953125\n",
      "0.0009765625\n",
      "0.00048828125\n",
      "0.000244140625\n",
      "0.0001220703125\n",
      "6.103515625e-05\n",
      "3.0517578125e-05\n",
      "1.52587890625e-05\n",
      "7.62939453125e-06\n",
      "3.814697265625e-06\n",
      "1.9073486328125e-06\n",
      "9.5367431640625e-07\n",
      "4.76837158203125e-07\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.4901161193847656e-08\n",
      "7.450580596923828e-09\n",
      "3.725290298461914e-09\n",
      "1.862645149230957e-09\n",
      "9.313225746154785e-10\n",
      "4.656612873077393e-10\n",
      "2.3283064365386963e-10\n",
      "1.1641532182693481e-10\n",
      "5.820766091346741e-11\n",
      "2.9103830456733704e-11\n",
      "1.4551915228366852e-11\n",
      "7.275957614183426e-12\n",
      "best cycle:  ['92', '222', '92']\n",
      "67\n",
      "106\n",
      "67\n",
      "Iteration number:  1\n",
      "Average unfairness:  27.490196078431374\n",
      "Average cost:  1.19544540455392\n",
      "neg cycle, alpha is  0.0030149066756139297\n",
      "['1401', '845', '1401']\n",
      "negative t-cycle was not fixed:  -0.0015639473\n",
      "Cost when correcting a negative cycle:  1.208896874789178\n",
      "Fairness when correcting a negative cycle:  22.509803921568626\n",
      "Fairness:  [32.470588235294116, 27.490196078431374]\n",
      "Cost:  [1.1903907713067448, 1.19544540455392]\n"
     ]
    }
   ],
   "source": [
    "# these are the iterations that the trade-off algorithm runs; note that beyond iteration 0, the starting clustering is no longer optimal in the optimization objective (for k-means, that means inertia)\n",
    "no_of_iterations = 6\n",
    "fairness_list = []\n",
    "cost_list = []\n",
    "\n",
    "# k is the number of clusters for spectral clustering\n",
    "#k = len(sizes) # for simulated model\n",
    "k = 2 # for the real data; needs to be varied\n",
    "\n",
    "\n",
    "# computing the spectrum of the graph\n",
    "A = nx.adjacency_matrix(G_SBM)\n",
    "# computing the normalized Laplacian of the graph\n",
    "L = nx.normalized_laplacian_matrix(G_SBM)\n",
    "L.todense()\n",
    "D = np.diag(np.sum(np.array(A.todense()), axis=1))\n",
    "\n",
    "# computing the eigenvalues and eigenvectors of the normalized Laplacian\n",
    "e, v = np.linalg.eig(L.todense())\n",
    "\n",
    "# only take the first k sorted eigenvalues (can start from 0 or from 1, since first is 0 given that we have one connected component often times)\n",
    "i = [list(e).index(j) for j in sorted(list(e))[1:k+1]]\n",
    "print(i)\n",
    "\n",
    "\n",
    "U = np.array(v[:, i])\n",
    "# performing manual spectral clustering: using the first k values of the eigenspace to do k-means \n",
    "#km = KMeans(init='k-means++', n_clusters=k, max_iter=200, n_init=200, verbose=0, random_state=3425)\n",
    "km = KMeans(init='k-means++', n_clusters=k, max_iter=200, n_init=200, verbose=0)\n",
    "\n",
    "km.fit(U)\n",
    "y = km.labels_\n",
    "# distances from the k-centers\n",
    "X_dist = km.transform(U)**2\n",
    "\n",
    "# keeping a copy of the clustering assignment\n",
    "y_copy = copy.deepcopy(y)\n",
    "print(y_copy)\n",
    "\n",
    "\n",
    "for iteration in range(no_of_iterations):\n",
    "    print(\"Iteration number: \",iteration)\n",
    "    # compute the cost and fairness of this clustering\n",
    "    # using closeness utility\n",
    "    #[_,avgf] = compute_util_avgprop_closeness(G_SBM, list_nodes,k,y)\n",
    "    # using statistical parity\n",
    "    [_,avgf] = compute_fairness_linear(G_SBM, list_nodes,k,y)\n",
    "    print(\"Average unfairness: \", avgf)  \n",
    "\n",
    "    fairness_list.append(avgf)\n",
    "    [_,avgcost] = compute_avg_kdistance_inertia(y,k,X_dist)\n",
    "    print(\"Average cost: \", avgcost)\n",
    "    cost_list.append(avgcost)\n",
    "    if avgf == 0:\n",
    "        break\n",
    "    # generating G_new with double weights\n",
    "    G_new = nx.DiGraph()\n",
    "    G_new.add_nodes_from(G_SBM)\n",
    "    G_new = doubly_weighted_G(G_SBM,G_new,list_nodes,y,k,X_dist)\n",
    "    list_nodes_Gnew = list(G_new.nodes())\n",
    "\n",
    "    length = {}\n",
    "    dis = {}\n",
    "    pre = {} \n",
    "    result = SPFA2(G_new)\n",
    "    # assert that G_new does not have a negative t-cycle; if it does, then len(result) == 3 and then we 'perturb' the weights to get rid of this negative t-cycle\n",
    "    if len(result) == 3:\n",
    "        # if we are not at the initial clustering\n",
    "        if iteration > 0:\n",
    "            #my_slope = compute_slope(fairness_list[iteration-1], cost_list[iteration-1], fairness_list[iteration], cost_list[iteration])\n",
    "            #myM = -1/my_slope\n",
    "            #epsilon = myM*1e-60\n",
    "            #print(\"M and slope:\", M, myM)\n",
    "            alpha = (cost_list[iteration-1] - cost_list[iteration]) / (fairness_list[iteration] - fairness_list[iteration - 1])\n",
    "            alpha += 2e-3\n",
    "            print(\"neg cycle, alpha is \", alpha)\n",
    "            for e in G_new.edges():\n",
    "                \n",
    "                #G_new[e[0]][e[1]]['tuv'] += G_new[e[0]][e[1]]['auv']/(myM+epsilon)\n",
    "                G_new[e[0]][e[1]]['tuv'] += alpha* G_new[e[0]][e[1]]['auv']\n",
    "                G_new[e[0]][e[1]]['tuv'] = round(G_new[e[0]][e[1]]['tuv'],10)\n",
    "        # if we are actually at the initial clustering (SC is not the optimal one); can ignore\n",
    "        #if iteration == 0:\n",
    "            #my_slope = compute_slope(0.2, 0, fairness_list[iteration], cost_list[iteration])\n",
    "            #myM = -1/my_slope\n",
    "            #epsilon = myM*1e-60\n",
    "            #print(\"M and slope:\", M, myM)\n",
    "            #for e in G_new.edges():\n",
    "            #    G_new[e[0]][e[1]]['tuv'] += G_new[e[0]][e[1]]['auv']/(myM+epsilon)\n",
    "            #    G_new[e[0]][e[1]]['tuv'] = round(G_new[e[0]][e[1]]['tuv'],10)\n",
    "                \n",
    "    length = {}\n",
    "    dis = {}\n",
    "    pre = {} \n",
    "    newresult = SPFA2(G_new) \n",
    "\n",
    "    # assert again that G_new does not have a negative t-cycle; if it does, then len(result) == 3 and then we see what clustering we get if we 'fix' the negative t-cycle\n",
    "    if len(newresult) == 3:\n",
    "        [vv,pre,stri] = newresult\n",
    "        negt = Trace(pre,vv)\n",
    "        print(negt)\n",
    "        sumcycle = 0\n",
    "        for i in range(len(negt) - 1):\n",
    "            sumcycle += G_new[negt[i]][negt[i+1]]['tuv']\n",
    "        print(\"negative t-cycle was not fixed: \", sumcycle)\n",
    "        y_neg = np.copy(y)\n",
    "        negt2 = copy.deepcopy(negt)\n",
    "        for i in range(len(negt)): \n",
    "            if type(negt[i]) == str:\n",
    "                negt2[i] = list_nodes.index(negt[i])\n",
    "        for i in range(len(negt2)):\n",
    "            if negt2[i] < len(G_SBM.nodes()):\n",
    "                if i == len(negt2) - 1:\n",
    "                    break\n",
    "                if negt2[i+1] < len(G_SBM.nodes()):\n",
    "                    y_neg[negt2[i]] = y[negt2[i+1]]\n",
    "                if negt2[i + 1] >= len(G_SBM.nodes()) and negt2[i+1] < len(G_SBM.nodes()) + k:\n",
    "                    y_neg[negt2[i]] = negt2[i+1] % len(G_SBM.nodes())\n",
    "        _,avgdistneg = compute_avg_kdistance_inertia(y_neg, k, X_dist)\n",
    "        # using closeness utility\n",
    "        #_,avgfairnessneg = compute_util_avgprop_closeness(G_SBM, list_nodes,k,y_neg)\n",
    "        # using statistical parity\n",
    "        _,avgfairnessneg = compute_fairness_linear(G_SBM, list_nodes,k,y_neg)\n",
    "        print(\"Cost when correcting a negative cycle: \", avgdistneg)\n",
    "        print(\"Fairness when correcting a negative cycle: \", avgfairnessneg)\n",
    "\n",
    "        break\n",
    "\n",
    "    length = {}\n",
    "    dis = {}\n",
    "    pre = {} \n",
    "\n",
    "    # we get to this point if we managed to fix the negative cycle (might have to run the previuos loop multiple times) or didn't have one to begin with\n",
    "     \n",
    "    print(\"we're finding Mlow\")\n",
    "\n",
    "    Mfind = 1\n",
    "    G_M = create_M_graph(G_SBM,G_new, Mfind)\n",
    "    mresult = SPFA(G_M)\n",
    "    if(len(mresult) != 3):\n",
    "        Mfind = 0\n",
    "        G_M = create_M_graph(G_SBM,G_new, Mfind)\n",
    "        assert(len(SPFA(G_M)) == 3)\n",
    "    else:\n",
    "        while True:\n",
    "            G_M = create_M_graph(G_SBM,G_new, Mfind)\n",
    "            if SPFA(G_M) == 'no negative cycle detected':\n",
    "                break\n",
    "            Mfind *= 2\n",
    "\n",
    "    # at this point, we perform a binary search \n",
    "    # initialize M and the limits for the binary search\n",
    "    M = Mfind/2\n",
    "    delta = Mfind/2\n",
    "    low = Mfind/2\n",
    "    high = Mfind\n",
    "\n",
    "    # binary search to find M for which there is a cycle of length 0\n",
    "    termination_condition = 10e-12\n",
    "    mids = []\n",
    "    while np.abs(delta) > termination_condition:\n",
    "        if high > low: \n",
    "            mid = (high + low) / 2\n",
    "            mids.append(mid)\n",
    "        G_M = create_M_graph(G_SBM,G_new, mid)\n",
    "        if SPFA(G_M) == 'no negative cycle detected':\n",
    "            delta = mid - low\n",
    "            high = mid\n",
    "        else:\n",
    "            delta = high - mid\n",
    "            low = mid\n",
    "        print(delta)\n",
    "    whereinmidsweare = 0\n",
    "    for mm in reversed(mids):\n",
    "        whereinmidsweare += 1\n",
    "        G_M = create_M_graph(G_SBM,G_new, mm)\n",
    "        if len(SPFA(G_M)) == 3:\n",
    "           break\n",
    "    if whereinmidsweare == len(mids):\n",
    "        break\n",
    "    M=mm\n",
    "\n",
    "    G_M = create_M_graph(G_SBM,G_new, M)\n",
    "    [v,pre,stri]=SPFA(G_M)\n",
    "    # this is the best cycle that, if followed, will get us the next best clustering with the minimal ratio of cost loss to fairness/utility increase\n",
    "    myc = Trace(pre,v)\n",
    "    print(\"best cycle: \",myc)\n",
    "    ytest = np.copy(y)\n",
    "    \n",
    "    myc2 = copy.deepcopy(myc)\n",
    "    # we 'follow' the best cycle in order to find that next best clustering, and will compute the cost and fairness/utility as we start the loop again in the next iteration\n",
    "    for i in range(len(myc)): \n",
    "        if type(myc[i]) == str:\n",
    "            myc2[i] = list_nodes.index(myc[i])\n",
    "    for i in range(len(myc2)):\n",
    "        print(myc2[i])\n",
    "        if myc2[i] < len(G_SBM.nodes()):\n",
    "            if i == len(myc2) - 1:\n",
    "                break\n",
    "            if myc2[i+1] < len(G_SBM.nodes()):\n",
    "                #a = y[myc2[i]]\n",
    "                ytest[myc2[i]] = y[myc2[i+1]]\n",
    "            if myc2[i + 1] >= len(G_SBM.nodes()) and myc2[i+1] < len(G_SBM.nodes()) + k:\n",
    "                print(myc2[i+1])\n",
    "                ytest[myc2[i]] = myc2[i+1] % len(G_SBM.nodes())\n",
    "    y = np.copy(ytest)\n",
    "\n",
    "print(\"Fairness: \", fairness_list)\n",
    "print(\"Cost: \", cost_list)\n",
    "#filename = 'SBM_n' + str(len(list_nodes)) + '_r' + str(ratio) + '_k' + str(k) + 'closeness-test.csv'\n",
    "#filename = 'Highschool_k' + str(k) + 'statparity_test.csv'\n",
    "#f = open(filename,'w')\n",
    "#writer=csv.writer(f,lineterminator=\"\\n\")\n",
    "#writer.writerow(fairness_list)\n",
    "#writer.writerow(cost_list)\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5882e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_centers = compute_centroids(G_SBM, list_nodes, k, y_copy,U)\n",
    "new_centers = compute_centroids(G_SBM, list_nodes, k, y,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1c99a9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0507766 ,  0.03258887])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_centers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d204f91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.05130796,  0.03362949]), array([ 0.07723217, -0.06454973])]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0e37329e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc289834210>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(old_centers[0][0],old_centers[0][1],color='b')\n",
    "plt.scatter(old_centers[1][0],old_centers[1][1],color='b')\n",
    "plt.scatter(new_centers[0][0],new_centers[0][1],color='orange')\n",
    "plt.scatter(new_centers[1][0],new_centers[1][1],color='orange')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67907826",
   "metadata": {},
   "source": [
    "### Testing out the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "34a96caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 0 0\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# these are the iterations that the trade-off algorithm runs; note that beyond iteration 0, the starting clustering is no longer optimal in the optimization objective (for k-means, that means inertia)\n",
    "no_of_iterations = 6\n",
    "fairness_list = []\n",
    "cost_list = []\n",
    "\n",
    "# k is the number of clusters for spectral clustering\n",
    "#k = len(sizes) # for simulated model\n",
    "k = 2 # for the real data; needs to be varied\n",
    "\n",
    "\n",
    "# computing the spectrum of the graph\n",
    "A = nx.adjacency_matrix(G_SBM)\n",
    "# computing the normalized Laplacian of the graph\n",
    "L = nx.normalized_laplacian_matrix(G_SBM)\n",
    "L.todense()\n",
    "D = np.diag(np.sum(np.array(A.todense()), axis=1))\n",
    "\n",
    "# computing the eigenvalues and eigenvectors of the normalized Laplacian\n",
    "e, v = np.linalg.eig(L.todense())\n",
    "\n",
    "# only take the first k sorted eigenvalues (can start from 0 or from 1, since first is 0 given that we have one connected component often times)\n",
    "i = [list(e).index(j) for j in sorted(list(e))[1:k+1]]\n",
    "print(i)\n",
    "\n",
    "\n",
    "U = np.array(v[:, i])\n",
    "# performing manual spectral clustering: using the first k values of the eigenspace to do k-means \n",
    "#km = KMeans(init='k-means++', n_clusters=k, max_iter=200, n_init=200, verbose=0, random_state=3425)\n",
    "km = KMeans(init='k-means++', n_clusters=k, max_iter=200, n_init=200, verbose=0)\n",
    "\n",
    "km.fit(U)\n",
    "y = km.labels_\n",
    "# distances from the k-centers\n",
    "X_dist = km.transform(U)**2\n",
    "\n",
    "# keeping a copy of the clustering assignment\n",
    "y_copy = copy.deepcopy(y)\n",
    "print(y_copy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bcfef3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average unfairness at C0:  32.470588235294116\n",
      "Average cost at C0:  1.1903907713067448\n"
     ]
    }
   ],
   "source": [
    "[_,avgf] = compute_fairness_linear(G_SBM, list_nodes,k,y)\n",
    "print(\"Average unfairness at C0: \", avgf)  \n",
    "\n",
    "fairness_list.append(avgf)\n",
    "[_,avgcost] = compute_avg_kdistance_inertia(y,k,X_dist)\n",
    "print(\"Average cost at C0: \", avgcost)\n",
    "cost_list.append(avgcost)\n",
    "if avgf == 0:\n",
    "    print(\"fairness is 0\")\n",
    "# generating G_new with double weights\n",
    "G_new = nx.DiGraph()\n",
    "G_new.add_nodes_from(G_SBM)\n",
    "G_new = doubly_weighted_G(G_SBM,G_new,list_nodes,y,k,X_dist)\n",
    "list_nodes_Gnew = list(G_new.nodes())\n",
    "\n",
    "length = {}\n",
    "dis = {}\n",
    "pre = {} \n",
    "result = SPFA2(G_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c9b1f491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no negative cycle detected'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e8aa71fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we're finding Mlow\n",
      "256.0\n",
      "128.0\n",
      "64.0\n",
      "32.0\n",
      "16.0\n",
      "8.0\n",
      "4.0\n",
      "2.0\n",
      "1.0\n",
      "0.5\n",
      "0.25\n",
      "0.125\n",
      "0.0625\n",
      "0.03125\n",
      "0.015625\n",
      "0.0078125\n",
      "0.00390625\n",
      "0.001953125\n",
      "0.0009765625\n",
      "0.00048828125\n",
      "0.000244140625\n",
      "0.0001220703125\n",
      "6.103515625e-05\n",
      "3.0517578125e-05\n",
      "1.52587890625e-05\n",
      "7.62939453125e-06\n",
      "3.814697265625e-06\n",
      "1.9073486328125e-06\n",
      "9.5367431640625e-07\n",
      "4.76837158203125e-07\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.4901161193847656e-08\n",
      "7.450580596923828e-09\n",
      "3.725290298461914e-09\n",
      "1.862645149230957e-09\n",
      "9.313225746154785e-10\n",
      "4.656612873077393e-10\n",
      "2.3283064365386963e-10\n",
      "1.1641532182693481e-10\n",
      "5.820766091346741e-11\n",
      "2.9103830456733704e-11\n",
      "1.4551915228366852e-11\n",
      "7.275957614183426e-12\n",
      "best cycle:  ['92', '222', '92']\n",
      "67\n",
      "106\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "length = {}\n",
    "dis = {}\n",
    "pre = {} \n",
    "\n",
    "# we get to this point if we managed to fix the negative cycle (might have to run the previuos loop multiple times) or didn't have one to begin with\n",
    "    \n",
    "print(\"we're finding Mlow\")\n",
    "\n",
    "Mfind = 1\n",
    "G_M = create_M_graph(G_SBM,G_new, Mfind)\n",
    "mresult = SPFA(G_M)\n",
    "if(len(mresult) != 3):\n",
    "    Mfind = 0\n",
    "    G_M = create_M_graph(G_SBM,G_new, Mfind)\n",
    "    assert(len(SPFA(G_M)) == 3)\n",
    "else:\n",
    "    while True:\n",
    "        G_M = create_M_graph(G_SBM,G_new, Mfind)\n",
    "        if SPFA(G_M) == 'no negative cycle detected':\n",
    "            break\n",
    "        Mfind *= 2\n",
    "\n",
    "# at this point, we perform a binary search \n",
    "# initialize M and the limits for the binary search\n",
    "M = Mfind/2\n",
    "delta = Mfind/2\n",
    "low = Mfind/2\n",
    "high = Mfind\n",
    "\n",
    "# binary search to find M for which there is a cycle of length 0\n",
    "termination_condition = 10e-12\n",
    "mids = []\n",
    "while np.abs(delta) > termination_condition:\n",
    "    if high > low: \n",
    "        mid = (high + low) / 2\n",
    "        mids.append(mid)\n",
    "    G_M = create_M_graph(G_SBM,G_new, mid)\n",
    "    if SPFA(G_M) == 'no negative cycle detected':\n",
    "        delta = mid - low\n",
    "        high = mid\n",
    "    else:\n",
    "        delta = high - mid\n",
    "        low = mid\n",
    "    print(delta)\n",
    "whereinmidsweare = 0\n",
    "for mm in reversed(mids):\n",
    "    whereinmidsweare += 1\n",
    "    G_M = create_M_graph(G_SBM,G_new, mm)\n",
    "    if len(SPFA(G_M)) == 3:\n",
    "        break\n",
    "    if whereinmidsweare == len(mids):\n",
    "        break\n",
    "M=mm\n",
    "\n",
    "G_M = create_M_graph(G_SBM,G_new, M)\n",
    "[v,pre,stri]=SPFA(G_M)\n",
    "# this is the best cycle that, if followed, will get us the next best clustering with the minimal ratio of cost loss to fairness/utility increase\n",
    "myc = Trace(pre,v)\n",
    "print(\"best cycle: \",myc)\n",
    "ytest = np.copy(y)\n",
    "\n",
    "myc2 = copy.deepcopy(myc)\n",
    "# we 'follow' the best cycle in order to find that next best clustering, and will compute the cost and fairness/utility as we start the loop again in the next iteration\n",
    "for i in range(len(myc)): \n",
    "    if type(myc[i]) == str:\n",
    "        myc2[i] = list_nodes.index(myc[i])\n",
    "for i in range(len(myc2)):\n",
    "    print(myc2[i])\n",
    "    if myc2[i] < len(G_SBM.nodes()):\n",
    "        if i == len(myc2) - 1:\n",
    "            break\n",
    "        if myc2[i+1] < len(G_SBM.nodes()):\n",
    "            #a = y[myc2[i]]\n",
    "            ytest[myc2[i]] = y[myc2[i+1]]\n",
    "        if myc2[i + 1] >= len(G_SBM.nodes()) and myc2[i+1] < len(G_SBM.nodes()) + k:\n",
    "            print(myc2[i+1])\n",
    "            ytest[myc2[i]] = myc2[i+1] % len(G_SBM.nodes())\n",
    "y = np.copy(ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4beed424",
   "metadata": {},
   "source": [
    "### Now y = C1, compute the new fairness, cost, and check for neg cycles in the doubly weighted graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ba52f980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average unfairness C1:  27.490196078431374\n",
      "Average cost C1:  1.19544540455392\n"
     ]
    }
   ],
   "source": [
    "[_,avgf] = compute_fairness_linear(G_SBM, list_nodes,k,y)\n",
    "print(\"Average unfairness C1: \", avgf)  \n",
    "\n",
    "fairness_list.append(avgf)\n",
    "[_,avgcost] = compute_avg_kdistance_inertia(y,k,X_dist)\n",
    "print(\"Average cost C1: \", avgcost)\n",
    "cost_list.append(avgcost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "741b5a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating G_new with double weights\n",
    "G_new = nx.DiGraph()\n",
    "G_new.add_nodes_from(G_SBM)\n",
    "G_new = doubly_weighted_G(G_SBM,G_new,list_nodes,y,k,X_dist)\n",
    "list_nodes_Gnew = list(G_new.nodes())\n",
    "\n",
    "length = {}\n",
    "dis = {}\n",
    "pre = {} \n",
    "result = SPFA2(G_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "595bcc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127,\n",
       " {'1': '222',\n",
       "  '55': '222',\n",
       "  '205': '222',\n",
       "  '272': '222',\n",
       "  '494': '222',\n",
       "  '779': '222',\n",
       "  '894': '222',\n",
       "  '3': '222',\n",
       "  '28': '222',\n",
       "  '147': '222',\n",
       "  '407': '222',\n",
       "  '674': '222',\n",
       "  '884': '222',\n",
       "  '27': '222',\n",
       "  '63': '92',\n",
       "  '173': '92',\n",
       "  '202': '222',\n",
       "  '327': '222',\n",
       "  '353': '222',\n",
       "  '429': '222',\n",
       "  '441': '222',\n",
       "  '492': '222',\n",
       "  '545': '222',\n",
       "  '32': '92',\n",
       "  '440': '92',\n",
       "  '624': '92',\n",
       "  '797': '92',\n",
       "  '920': '92',\n",
       "  '151': '92',\n",
       "  '277': '92',\n",
       "  '502': '92',\n",
       "  '866': '92',\n",
       "  '45': '222',\n",
       "  '48': '222',\n",
       "  '79': '222',\n",
       "  '335': '222',\n",
       "  '496': '222',\n",
       "  '601': '222',\n",
       "  '765': '222',\n",
       "  '46': '222',\n",
       "  '117': '222',\n",
       "  '196': '222',\n",
       "  '257': '222',\n",
       "  '268': '222',\n",
       "  '170': '222',\n",
       "  '252': '222',\n",
       "  '883': '222',\n",
       "  '61': '92',\n",
       "  '125': '92',\n",
       "  '70': '222',\n",
       "  '101': '222',\n",
       "  '132': '222',\n",
       "  '240': '222',\n",
       "  '425': '222',\n",
       "  '447': '222',\n",
       "  '72': '222',\n",
       "  '857': '222',\n",
       "  '80': '222',\n",
       "  '120': '222',\n",
       "  '285': '222',\n",
       "  '468': '92',\n",
       "  '85': '222',\n",
       "  '190': '222',\n",
       "  '213': '222',\n",
       "  '214': '222',\n",
       "  '603': '222',\n",
       "  '605': '92',\n",
       "  '92': '222',\n",
       "  '845': '222',\n",
       "  '119': '222',\n",
       "  '122': '222',\n",
       "  '343': '222',\n",
       "  '364': '222',\n",
       "  '265': '222',\n",
       "  '465': '222',\n",
       "  '587': '222',\n",
       "  '488': '222',\n",
       "  '255': '92',\n",
       "  '248': '92',\n",
       "  '325': '92',\n",
       "  '491': '92',\n",
       "  '622': '92',\n",
       "  '960': '92',\n",
       "  '134': '222',\n",
       "  '388': '222',\n",
       "  '184': '222',\n",
       "  '38': '92',\n",
       "  '201': '92',\n",
       "  '452': '92',\n",
       "  '634': '92',\n",
       "  '642': '92',\n",
       "  '691': '92',\n",
       "  '694': '92',\n",
       "  '753': '92',\n",
       "  '869': '92',\n",
       "  '156': '92',\n",
       "  '159': '92',\n",
       "  '165': '222',\n",
       "  '498': '222',\n",
       "  '1332': '92',\n",
       "  '200': '222',\n",
       "  '480': '222',\n",
       "  '245': '92',\n",
       "  '211': '222',\n",
       "  '242': '222',\n",
       "  '219': '92',\n",
       "  '222': '92',\n",
       "  '867': '222',\n",
       "  '232': '222',\n",
       "  '798': '92',\n",
       "  '959': '92',\n",
       "  '564': '92',\n",
       "  '275': '92',\n",
       "  '312': '92',\n",
       "  '612': '92',\n",
       "  '769': '92',\n",
       "  '486': '222',\n",
       "  '531': '222',\n",
       "  '771': '222',\n",
       "  '520': '92',\n",
       "  '576': '92',\n",
       "  '577': '92',\n",
       "  '1401': '92',\n",
       "  '1228': '92',\n",
       "  '1519': '92',\n",
       "  '1594': '92',\n",
       "  '1828': '92',\n",
       "  127: 129,\n",
       "  128: '222',\n",
       "  129: 128},\n",
       " 'negative cycle detected')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9fc7c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ab749425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1903907713067448, 1.19544540455392]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d31597d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32.470588235294116, 27.490196078431374]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "127bce22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg cycle, alpha is  0.0030149066756139297\n",
      "compute metric with alpha for C0:  1.0924949780750455\n",
      "compute metric with alpha for C1:  1.1125650288831215\n"
     ]
    }
   ],
   "source": [
    "alpha = (cost_list[iteration-1] - cost_list[iteration]) / (fairness_list[iteration] - fairness_list[iteration - 1])\n",
    "alpha += 2e-3\n",
    "print(\"neg cycle, alpha is \", alpha)\n",
    "print(\"compute metric with alpha for C0: \", cost_list[iteration-1] + alpha*fairness_list[iteration - 1])\n",
    "print(\"compute metric with alpha for C1: \", cost_list[iteration] + alpha*fairness_list[iteration])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c10ac9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['92', '222', '92']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2062d901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb7f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6326431b",
   "metadata": {},
   "source": [
    "cluster 127 -> C_0 \n",
    "cluster 128 -> C_1 \n",
    "cluster 129 -> start \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "79154739",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qc/k6jgnl3532x82rw058f_4nj40002pv/T/ipykernel_9298/2575267836.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'222'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/networkx/classes/coreviews.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atlas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 128"
     ]
    }
   ],
   "source": [
    "G_new['222'][128]['auv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a2d51f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009960784313725317\n"
     ]
    }
   ],
   "source": [
    "# myc is the best cycle that we followed \n",
    "# compute m(myc)\n",
    "m_myc = 0\n",
    "for i in range(len(myc) - 1):\n",
    "     m_myc += G_new[myc[i]][myc[i+1]]['tuv'] + alpha*G_new[myc[i]][myc[i+1]]['auv']\n",
    "print(m_myc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82bece0a",
   "metadata": {},
   "source": [
    "### fixing a negative cycle until there are no more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4f283e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 0 0\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0]\n",
      "Iteration number:  0\n",
      "Average unfairness:  32.470588235294116\n",
      "Average cost:  1.1903907713067448\n",
      "we're finding Mlow\n",
      "256.0\n",
      "128.0\n",
      "64.0\n",
      "32.0\n",
      "16.0\n",
      "8.0\n",
      "4.0\n",
      "2.0\n",
      "1.0\n",
      "0.5\n",
      "0.25\n",
      "0.125\n",
      "0.0625\n",
      "0.03125\n",
      "0.015625\n",
      "0.0078125\n",
      "0.00390625\n",
      "0.001953125\n",
      "0.0009765625\n",
      "0.00048828125\n",
      "0.000244140625\n",
      "0.0001220703125\n",
      "6.103515625e-05\n",
      "3.0517578125e-05\n",
      "1.52587890625e-05\n",
      "7.62939453125e-06\n",
      "3.814697265625e-06\n",
      "1.9073486328125e-06\n",
      "9.5367431640625e-07\n",
      "4.76837158203125e-07\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.4901161193847656e-08\n",
      "7.450580596923828e-09\n",
      "3.725290298461914e-09\n",
      "1.862645149230957e-09\n",
      "9.313225746154785e-10\n",
      "4.656612873077393e-10\n",
      "2.3283064365386963e-10\n",
      "1.1641532182693481e-10\n",
      "5.820766091346741e-11\n",
      "2.9103830456733704e-11\n",
      "1.4551915228366852e-11\n",
      "7.275957614183426e-12\n",
      "best cycle:  ['92', '222', '92']\n",
      "67\n",
      "106\n",
      "67\n",
      "Iteration number:  1\n",
      "Average unfairness:  27.490196078431374\n",
      "Average cost:  1.19544540455392\n",
      "neg cycle, alpha is  0.0030149066756139297\n",
      "compute metric with alpha for C0:  1.288286564538444\n",
      "compute metric with alpha for C1:  1.2783257802247185\n",
      "['1401', '845', '1401']\n",
      "negative t-cycle was not fixed:  -0.0015639473\n",
      "neg cycle was not fixed, these are the weights:  [-0.0035324082, 0.0019684609] [-2.4901960784313744, -2.4901960784313744]\n",
      "Cost when correcting a negative cycle:  1.208896874789178\n",
      "Fairness when correcting a negative cycle:  22.509803921568626\n",
      "compute metric for following the neg cycle:  1.2767618328990757\n",
      "['1828', '211', '1828']\n",
      "negative t-cycle was not fixed:  -0.0008149697\n",
      "Cost when correcting a negative cycle:  1.2230973226713902\n",
      "Fairness when correcting a negative cycle:  17.529411764705884\n",
      "compute metric for following the neg cycle:  1.2759468632203872\n",
      "we're finding Mlow\n",
      "4096.0\n",
      "2048.0\n",
      "1024.0\n",
      "512.0\n",
      "256.0\n",
      "128.0\n",
      "64.0\n",
      "32.0\n",
      "16.0\n",
      "8.0\n",
      "4.0\n",
      "2.0\n",
      "1.0\n",
      "0.5\n",
      "0.25\n",
      "0.125\n",
      "0.0625\n",
      "0.03125\n",
      "0.015625\n",
      "0.0078125\n",
      "0.00390625\n",
      "0.001953125\n",
      "0.0009765625\n",
      "0.00048828125\n",
      "0.000244140625\n",
      "0.0001220703125\n",
      "6.103515625e-05\n",
      "3.0517578125e-05\n",
      "1.52587890625e-05\n",
      "7.62939453125e-06\n",
      "3.814697265625e-06\n",
      "1.9073486328125e-06\n",
      "9.5367431640625e-07\n",
      "4.76837158203125e-07\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.4901161193847656e-08\n",
      "7.450580596923828e-09\n",
      "3.725290298461914e-09\n",
      "1.862645149230957e-09\n",
      "9.313225746154785e-10\n",
      "4.656612873077393e-10\n",
      "2.3283064365386963e-10\n",
      "1.1641532182693481e-10\n",
      "5.820766091346741e-11\n",
      "2.9103830456733704e-11\n",
      "1.4551915228366852e-11\n",
      "7.275957614183426e-12\n",
      "best cycle:  ['1228', '242', '1228']\n",
      "123\n",
      "104\n",
      "123\n",
      "Iteration number:  2\n",
      "Average unfairness:  22.509803921568626\n",
      "Average cost:  1.2109748118924515\n",
      "neg cycle, alpha is  0.005118109347500412\n",
      "compute metric with alpha for C0:  1.3361432340675587\n",
      "compute metric with alpha for C1:  1.3261824497538333\n",
      "['211', '159', '211']\n",
      "negative t-cycle was not fixed:  -0.0095717767\n",
      "neg cycle was not fixed, these are the weights:  [-0.0044270393, -0.0051447374] [-2.4901960784313744, -2.4901960784313673]\n",
      "Cost when correcting a negative cycle:  1.2268932267914492\n",
      "Fairness when correcting a negative cycle:  17.529411764705884\n",
      "compute metric for following the neg cycle:  1.316610673000574\n",
      "['232', '248', '232']\n",
      "negative t-cycle was not fixed:  -0.0035733105000000003\n",
      "Cost when correcting a negative cycle:  1.2488101079899365\n",
      "Fairness when correcting a negative cycle:  12.549019607843128\n",
      "compute metric for following the neg cycle:  1.3130373625468044\n",
      "['1228', '1401', '1228']\n",
      "negative t-cycle was not fixed:  -0.0017889314999999999\n",
      "Cost when correcting a negative cycle:  1.2470211764782109\n",
      "Fairness when correcting a negative cycle:  12.549019607843128\n",
      "compute metric for following the neg cycle:  1.3112484310350787\n",
      "['867', '38', '867']\n",
      "negative t-cycle was not fixed:  -0.0004988192999999998\n",
      "Cost when correcting a negative cycle:  1.272012548858644\n",
      "Fairness when correcting a negative cycle:  7.568627450980394\n",
      "compute metric for following the neg cycle:  1.3107496117632549\n",
      "['1828', '845', '1828']\n",
      "negative t-cycle was not fixed:  -0.011578749400000001\n",
      "Cost when correcting a negative cycle:  1.2859239911493083\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.2991708624016625\n",
      "['1228', '38', '1228']\n",
      "negative t-cycle was not fixed:  -0.0055592825\n",
      "Cost when correcting a negative cycle:  1.2803647086669576\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.2936115799193117\n",
      "we're finding Mlow\n",
      "2.0\n",
      "1.0\n",
      "0.5\n",
      "0.25\n",
      "0.125\n",
      "0.0625\n",
      "0.03125\n",
      "0.015625\n",
      "0.0078125\n",
      "0.00390625\n",
      "0.001953125\n",
      "0.0009765625\n",
      "0.00048828125\n",
      "0.000244140625\n",
      "0.0001220703125\n",
      "6.103515625e-05\n",
      "3.0517578125e-05\n",
      "1.52587890625e-05\n",
      "7.62939453125e-06\n",
      "3.814697265625e-06\n",
      "1.9073486328125e-06\n",
      "9.5367431640625e-07\n",
      "4.76837158203125e-07\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.4901161193847656e-08\n",
      "7.450580596923828e-09\n",
      "3.725290298461914e-09\n",
      "1.862645149230957e-09\n",
      "9.313225746154785e-10\n",
      "4.656612873077393e-10\n",
      "2.3283064365386963e-10\n",
      "1.1641532182693481e-10\n",
      "5.820766091346741e-11\n",
      "2.9103830456733704e-11\n",
      "1.4551915228366852e-11\n",
      "7.275957614183426e-12\n",
      "best cycle:  ['38', '531', '38']\n",
      "86\n",
      "117\n",
      "86\n",
      "Iteration number:  3\n",
      "Average unfairness:  17.529411764705884\n",
      "Average cost:  1.2377811549424165\n",
      "neg cycle, alpha is  0.007382375966725257\n",
      "compute metric with alpha for C0:  1.3771506473787376\n",
      "compute metric with alpha for C1:  1.3671898630650121\n",
      "['486', '564', '486']\n",
      "negative t-cycle was not fixed:  -0.0047328634\n",
      "neg cycle was not fixed, these are the weights:  [-0.0041085368, -0.0006243266] [-2.4901960784313744, -2.4901960784313815]\n",
      "Cost when correcting a negative cycle:  1.2698154189431536\n",
      "Fairness when correcting a negative cycle:  12.549019607843128\n",
      "compute metric for following the neg cycle:  1.3624569997020588\n",
      "['1228', '1401', '1228']\n",
      "negative t-cycle was not fixed:  -0.0017889314999999999\n",
      "Cost when correcting a negative cycle:  1.268026487431428\n",
      "Fairness when correcting a negative cycle:  12.549019607843128\n",
      "compute metric for following the neg cycle:  1.3606680681903331\n",
      "['1828', '232', '1828']\n",
      "negative t-cycle was not fixed:  -0.0208454876\n",
      "Cost when correcting a negative cycle:  1.2839481272589417\n",
      "Fairness when correcting a negative cycle:  7.568627450980394\n",
      "compute metric for following the neg cycle:  1.3398225806541564\n",
      "['1228', '867', '1228']\n",
      "negative t-cycle was not fixed:  -0.0173350374\n",
      "Cost when correcting a negative cycle:  1.3033802171570241\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.3224875431885483\n",
      "['486', '845', '486']\n",
      "negative t-cycle was not fixed:  -0.0107268664\n",
      "Cost when correcting a negative cycle:  1.292653350748585\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.311760676780109\n",
      "['564', '159', '564']\n",
      "negative t-cycle was not fixed:  -0.005677988300000001\n",
      "Cost when correcting a negative cycle:  1.2869753624637368\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.306082688495261\n",
      "['211', '531', '211']\n",
      "negative t-cycle was not fixed:  -0.0057176533\n",
      "Cost when correcting a negative cycle:  1.281257709234654\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.3003650352661782\n",
      "['38', '248', '38']\n",
      "negative t-cycle was not fixed:  -0.0008930006\n",
      "Cost when correcting a negative cycle:  1.2803647086669576\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.2994720346984818\n",
      "we're finding Mlow\n",
      "2.0\n",
      "1.0\n",
      "0.5\n",
      "0.25\n",
      "0.125\n",
      "0.0625\n",
      "0.03125\n",
      "0.015625\n",
      "0.0078125\n",
      "0.00390625\n",
      "0.001953125\n",
      "0.0009765625\n",
      "0.00048828125\n",
      "0.000244140625\n",
      "0.0001220703125\n",
      "6.103515625e-05\n",
      "3.0517578125e-05\n",
      "1.52587890625e-05\n",
      "7.62939453125e-06\n",
      "3.814697265625e-06\n",
      "1.9073486328125e-06\n",
      "9.5367431640625e-07\n",
      "4.76837158203125e-07\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.4901161193847656e-08\n",
      "7.450580596923828e-09\n",
      "3.725290298461914e-09\n",
      "1.862645149230957e-09\n",
      "9.313225746154785e-10\n",
      "4.656612873077393e-10\n",
      "2.3283064365386963e-10\n",
      "1.1641532182693481e-10\n",
      "5.820766091346741e-11\n",
      "2.9103830456733704e-11\n",
      "1.4551915228366852e-11\n",
      "7.275957614183426e-12\n",
      "best cycle:  ['38', '531', '38']\n",
      "86\n",
      "117\n",
      "86\n",
      "Iteration number:  4\n",
      "Average unfairness:  22.509803921568626\n",
      "Average cost:  1.2109748118924515\n",
      "neg cycle, alpha is  0.007382375966725257\n",
      "compute metric with alpha for C0:  1.3671898630650121\n",
      "compute metric with alpha for C1:  1.3771506473787376\n",
      "['531', '564', '531']\n",
      "negative t-cycle was not fixed:  -0.009453070899999999\n",
      "neg cycle was not fixed, these are the weights:  [-0.0072568463, -0.0021962246] [-2.4901960784313744, -2.4901960784313673]\n",
      "Cost when correcting a negative cycle:  1.2382888683053799\n",
      "Fairness when correcting a negative cycle:  17.529411764705884\n",
      "compute metric for following the neg cycle:  1.3676975764279755\n",
      "['486', '798', '486']\n",
      "negative t-cycle was not fixed:  -0.0015032811999999996\n",
      "Cost when correcting a negative cycle:  1.273552714563498\n",
      "Fairness when correcting a negative cycle:  12.549019607843128\n",
      "compute metric for following the neg cycle:  1.366194295322403\n",
      "['1228', '1401', '1228']\n",
      "negative t-cycle was not fixed:  -0.0017889314999999999\n",
      "Cost when correcting a negative cycle:  1.2717637830517723\n",
      "Fairness when correcting a negative cycle:  12.549019607843128\n",
      "compute metric for following the neg cycle:  1.3644053638106775\n",
      "['1828', '232', '1828']\n",
      "negative t-cycle was not fixed:  -0.0208454876\n",
      "Cost when correcting a negative cycle:  1.2876854228792862\n",
      "Fairness when correcting a negative cycle:  7.568627450980394\n",
      "compute metric for following the neg cycle:  1.343559876274501\n",
      "['1228', '867', '1228']\n",
      "negative t-cycle was not fixed:  -0.0173350374\n",
      "Cost when correcting a negative cycle:  1.3071175127773684\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.3262248388088926\n",
      "['845', '486', '845']\n",
      "negative t-cycle was not fixed:  -0.0107268664\n",
      "Cost when correcting a negative cycle:  1.2963906463689292\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.3154979724004534\n",
      "['798', '159', '798']\n",
      "negative t-cycle was not fixed:  -0.0089075706\n",
      "Cost when correcting a negative cycle:  1.2874830758267006\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.3065904018582248\n",
      "['211', '531', '211']\n",
      "negative t-cycle was not fixed:  -0.0057176533\n",
      "Cost when correcting a negative cycle:  1.2817654225976176\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.3008727486291418\n",
      "['564', '248', '564']\n",
      "negative t-cycle was not fixed:  -0.0014007139\n",
      "Cost when correcting a negative cycle:  1.2803647086669576\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.2994720346984818\n",
      "we're finding Mlow\n",
      "2.0\n",
      "1.0\n",
      "0.5\n",
      "0.25\n",
      "0.125\n",
      "0.0625\n",
      "0.03125\n",
      "0.015625\n",
      "0.0078125\n",
      "0.00390625\n",
      "0.001953125\n",
      "0.0009765625\n",
      "0.00048828125\n",
      "0.000244140625\n",
      "0.0001220703125\n",
      "6.103515625e-05\n",
      "3.0517578125e-05\n",
      "1.52587890625e-05\n",
      "7.62939453125e-06\n",
      "3.814697265625e-06\n",
      "1.9073486328125e-06\n",
      "9.5367431640625e-07\n",
      "4.76837158203125e-07\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.4901161193847656e-08\n",
      "7.450580596923828e-09\n",
      "3.725290298461914e-09\n",
      "1.862645149230957e-09\n",
      "9.313225746154785e-10\n",
      "4.656612873077393e-10\n",
      "2.3283064365386963e-10\n",
      "1.1641532182693481e-10\n",
      "5.820766091346741e-11\n",
      "2.9103830456733704e-11\n",
      "1.4551915228366852e-11\n",
      "7.275957614183426e-12\n",
      "best cycle:  ['38', '531', '38']\n",
      "86\n",
      "117\n",
      "86\n",
      "Iteration number:  5\n",
      "Average unfairness:  17.529411764705884\n",
      "Average cost:  1.2377811549424165\n",
      "neg cycle, alpha is  0.007382375966725257\n",
      "compute metric with alpha for C0:  1.3771506473787376\n",
      "compute metric with alpha for C1:  1.3671898630650121\n",
      "['486', '564', '486']\n",
      "negative t-cycle was not fixed:  -0.0047328634\n",
      "neg cycle was not fixed, these are the weights:  [-0.0041085368, -0.0006243266] [-2.4901960784313744, -2.4901960784313815]\n",
      "Cost when correcting a negative cycle:  1.2698154189431536\n",
      "Fairness when correcting a negative cycle:  12.549019607843128\n",
      "compute metric for following the neg cycle:  1.3624569997020588\n",
      "['1228', '1401', '1228']\n",
      "negative t-cycle was not fixed:  -0.0017889314999999999\n",
      "Cost when correcting a negative cycle:  1.268026487431428\n",
      "Fairness when correcting a negative cycle:  12.549019607843128\n",
      "compute metric for following the neg cycle:  1.3606680681903331\n",
      "['1828', '232', '1828']\n",
      "negative t-cycle was not fixed:  -0.0208454876\n",
      "Cost when correcting a negative cycle:  1.2839481272589417\n",
      "Fairness when correcting a negative cycle:  7.568627450980394\n",
      "compute metric for following the neg cycle:  1.3398225806541564\n",
      "['1228', '867', '1228']\n",
      "negative t-cycle was not fixed:  -0.0173350374\n",
      "Cost when correcting a negative cycle:  1.3033802171570241\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.3224875431885483\n",
      "['486', '845', '486']\n",
      "negative t-cycle was not fixed:  -0.0107268664\n",
      "Cost when correcting a negative cycle:  1.292653350748585\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.311760676780109\n",
      "['564', '159', '564']\n",
      "negative t-cycle was not fixed:  -0.005677988300000001\n",
      "Cost when correcting a negative cycle:  1.2869753624637368\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.306082688495261\n",
      "['211', '531', '211']\n",
      "negative t-cycle was not fixed:  -0.0057176533\n",
      "Cost when correcting a negative cycle:  1.281257709234654\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.3003650352661782\n",
      "['38', '248', '38']\n",
      "negative t-cycle was not fixed:  -0.0008930006\n",
      "Cost when correcting a negative cycle:  1.2803647086669576\n",
      "Fairness when correcting a negative cycle:  2.588235294117652\n",
      "compute metric for following the neg cycle:  1.2994720346984818\n",
      "we're finding Mlow\n",
      "2.0\n",
      "1.0\n",
      "0.5\n",
      "0.25\n",
      "0.125\n",
      "0.0625\n",
      "0.03125\n",
      "0.015625\n",
      "0.0078125\n",
      "0.00390625\n",
      "0.001953125\n",
      "0.0009765625\n",
      "0.00048828125\n",
      "0.000244140625\n",
      "0.0001220703125\n",
      "6.103515625e-05\n",
      "3.0517578125e-05\n",
      "1.52587890625e-05\n",
      "7.62939453125e-06\n",
      "3.814697265625e-06\n",
      "1.9073486328125e-06\n",
      "9.5367431640625e-07\n",
      "4.76837158203125e-07\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.4901161193847656e-08\n",
      "7.450580596923828e-09\n",
      "3.725290298461914e-09\n",
      "1.862645149230957e-09\n",
      "9.313225746154785e-10\n",
      "4.656612873077393e-10\n",
      "2.3283064365386963e-10\n",
      "1.1641532182693481e-10\n",
      "5.820766091346741e-11\n",
      "2.9103830456733704e-11\n",
      "1.4551915228366852e-11\n",
      "7.275957614183426e-12\n",
      "best cycle:  ['38', '531', '38']\n",
      "86\n",
      "117\n",
      "86\n",
      "Fairness:  [32.470588235294116, 27.490196078431374, 22.509803921568626, 17.529411764705884, 22.509803921568626, 17.529411764705884]\n",
      "Cost:  [1.1903907713067448, 1.19544540455392, 1.2109748118924515, 1.2377811549424165, 1.2109748118924515, 1.2377811549424165]\n"
     ]
    }
   ],
   "source": [
    "# these are the iterations that the trade-off algorithm runs; note that beyond iteration 0, the starting clustering is no longer optimal in the optimization objective (for k-means, that means inertia)\n",
    "no_of_iterations = 6\n",
    "fairness_list = []\n",
    "cost_list = []\n",
    "\n",
    "# k is the number of clusters for spectral clustering\n",
    "#k = len(sizes) # for simulated model\n",
    "k = 2 # for the real data; needs to be varied\n",
    "\n",
    "\n",
    "# computing the spectrum of the graph\n",
    "A = nx.adjacency_matrix(G_SBM)\n",
    "# computing the normalized Laplacian of the graph\n",
    "L = nx.normalized_laplacian_matrix(G_SBM)\n",
    "L.todense()\n",
    "D = np.diag(np.sum(np.array(A.todense()), axis=1))\n",
    "\n",
    "# computing the eigenvalues and eigenvectors of the normalized Laplacian\n",
    "e, v = np.linalg.eig(L.todense())\n",
    "\n",
    "# only take the first k sorted eigenvalues (can start from 0 or from 1, since first is 0 given that we have one connected component often times)\n",
    "i = [list(e).index(j) for j in sorted(list(e))[1:k+1]]\n",
    "print(i)\n",
    "\n",
    "\n",
    "U = np.array(v[:, i])\n",
    "# performing manual spectral clustering: using the first k values of the eigenspace to do k-means \n",
    "#km = KMeans(init='k-means++', n_clusters=k, max_iter=200, n_init=200, verbose=0, random_state=3425)\n",
    "km = KMeans(init='k-means++', n_clusters=k, max_iter=200, n_init=200, verbose=0)\n",
    "\n",
    "km.fit(U)\n",
    "y = km.labels_\n",
    "# distances from the k-centers\n",
    "X_dist = km.transform(U)**2\n",
    "\n",
    "# keeping a copy of the clustering assignment\n",
    "y_copy = copy.deepcopy(y)\n",
    "print(y_copy)\n",
    "\n",
    "\n",
    "for iteration in range(no_of_iterations):\n",
    "    print(\"Iteration number: \",iteration)\n",
    "    # compute the cost and fairness of this clustering\n",
    "    # using closeness utility\n",
    "    #[_,avgf] = compute_util_avgprop_closeness(G_SBM, list_nodes,k,y)\n",
    "    # using statistical parity\n",
    "    [_,avgf] = compute_fairness_linear(G_SBM, list_nodes,k,y)\n",
    "    print(\"Average unfairness: \", avgf)  \n",
    "\n",
    "    fairness_list.append(avgf)\n",
    "    [_,avgcost] = compute_avg_kdistance_inertia(y,k,X_dist)\n",
    "    print(\"Average cost: \", avgcost)\n",
    "    cost_list.append(avgcost)\n",
    "    if avgf == 0:\n",
    "        break\n",
    "    # generating G_new with double weights\n",
    "    G_new = nx.DiGraph()\n",
    "    G_new.add_nodes_from(G_SBM)\n",
    "    G_new = doubly_weighted_G(G_SBM,G_new,list_nodes,y,k,X_dist)\n",
    "    list_nodes_Gnew = list(G_new.nodes())\n",
    "\n",
    "    length = {}\n",
    "    dis = {}\n",
    "    pre = {} \n",
    "    result = SPFA2(G_new)\n",
    "    # assert that G_new does not have a negative t-cycle; if it does, then len(result) == 3 and then we 'perturb' the weights to get rid of this negative t-cycle\n",
    "    if len(result) == 3:\n",
    "        # if we are not at the initial clustering\n",
    "        if iteration > 0:\n",
    "            #my_slope = compute_slope(fairness_list[iteration-1], cost_list[iteration-1], fairness_list[iteration], cost_list[iteration])\n",
    "            #myM = -1/my_slope\n",
    "            #epsilon = myM*1e-60\n",
    "            #print(\"M and slope:\", M, myM)\n",
    "            alpha = (cost_list[iteration-1] - cost_list[iteration]) / (fairness_list[iteration] - fairness_list[iteration - 1])\n",
    "            alpha += 2e-3\n",
    "            print(\"neg cycle, alpha is \", alpha)\n",
    "            print(\"compute metric with alpha for C0: \", cost_list[iteration-1] + alpha*fairness_list[iteration - 1])\n",
    "            print(\"compute metric with alpha for C1: \", cost_list[iteration] + alpha*fairness_list[iteration])\n",
    "            for e in G_new.edges():\n",
    "                \n",
    "                #G_new[e[0]][e[1]]['tuv'] += G_new[e[0]][e[1]]['auv']/(myM+epsilon)\n",
    "                G_new[e[0]][e[1]]['tuv'] += alpha* G_new[e[0]][e[1]]['auv']\n",
    "                G_new[e[0]][e[1]]['tuv'] = round(G_new[e[0]][e[1]]['tuv'],10)\n",
    "        # if we are actually at the initial clustering (SC is not the optimal one); can ignore\n",
    "        #if iteration == 0:\n",
    "            #my_slope = compute_slope(0.2, 0, fairness_list[iteration], cost_list[iteration])\n",
    "            #myM = -1/my_slope\n",
    "            #epsilon = myM*1e-60\n",
    "            #print(\"M and slope:\", M, myM)\n",
    "            #for e in G_new.edges():\n",
    "            #    G_new[e[0]][e[1]]['tuv'] += G_new[e[0]][e[1]]['auv']/(myM+epsilon)\n",
    "            #    G_new[e[0]][e[1]]['tuv'] = round(G_new[e[0]][e[1]]['tuv'],10)\n",
    "                \n",
    "    length = {}\n",
    "    dis = {}\n",
    "    pre = {} \n",
    "    newresult = SPFA2(G_new) \n",
    "\n",
    "    if len(newresult) == 3:\n",
    "        [vv,pre,stri] = newresult\n",
    "        negt = Trace(pre,vv)\n",
    "        print(negt)\n",
    "        sumcycle = 0\n",
    "        t_weights_negt = []\n",
    "        a_weights_negt = []\n",
    "        for i in range(len(negt) - 1):\n",
    "            sumcycle += G_new[negt[i]][negt[i+1]]['tuv']\n",
    "            t_weights_negt.append(G_new[negt[i]][negt[i+1]]['tuv'])\n",
    "            a_weights_negt.append(G_new[negt[i]][negt[i+1]]['auv'])\n",
    "        print(\"negative t-cycle was not fixed: \", sumcycle)\n",
    "        print(\"neg cycle was not fixed, these are the weights: \", t_weights_negt, a_weights_negt)\n",
    "        y_neg = np.copy(y)\n",
    "        negt2 = copy.deepcopy(negt)\n",
    "        for i in range(len(negt)): \n",
    "            if type(negt[i]) == str:\n",
    "                negt2[i] = list_nodes.index(negt[i])\n",
    "        for i in range(len(negt2)):\n",
    "            if negt2[i] < len(G_SBM.nodes()):\n",
    "                if i == len(negt2) - 1:\n",
    "                    break\n",
    "                if negt2[i+1] < len(G_SBM.nodes()):\n",
    "                    y_neg[negt2[i]] = y[negt2[i+1]]\n",
    "                if negt2[i + 1] >= len(G_SBM.nodes()) and negt2[i+1] < len(G_SBM.nodes()) + k:\n",
    "                    y_neg[negt2[i]] = negt2[i+1] % len(G_SBM.nodes())\n",
    "        _,avgdistneg = compute_avg_kdistance_inertia(y_neg, k, X_dist)\n",
    "        # using closeness utility\n",
    "        #_,avgfairnessneg = compute_util_avgprop_closeness(G_SBM, list_nodes,k,y_neg)\n",
    "        # using statistical parity\n",
    "        _,avgfairnessneg = compute_fairness_linear(G_SBM, list_nodes,k,y_neg)\n",
    "        print(\"Cost when correcting a negative cycle: \", avgdistneg)\n",
    "        print(\"Fairness when correcting a negative cycle: \", avgfairnessneg)\n",
    "        print(\"compute metric for following the neg cycle: \", avgdistneg + alpha*avgfairnessneg)\n",
    "\n",
    "        #break\n",
    "\n",
    "    # assert again that G_new does not have a negative t-cycle; if it does, then len(result) == 3 and then we see what clustering we get if we 'fix' the negative t-cycle\n",
    "    # this is an example of a loop that 'fixes' negative cycles until there are no more (until we get to the optimal cycle in the objective set)\n",
    "    if iteration > 0:\n",
    "        while True:    \n",
    "            G_new = nx.DiGraph()\n",
    "            G_new.add_nodes_from(G_SBM)\n",
    "            G_new = doubly_weighted_G(G_SBM,G_new,list_nodes,y_neg,k,X_dist)\n",
    "\n",
    "            for e in G_new.edges():\n",
    "                \n",
    "                #G_new[e[0]][e[1]]['tuv'] += G_new[e[0]][e[1]]['auv']/(myM+epsilon)\n",
    "                G_new[e[0]][e[1]]['tuv'] += alpha* G_new[e[0]][e[1]]['auv']\n",
    "                G_new[e[0]][e[1]]['tuv'] = round(G_new[e[0]][e[1]]['tuv'],10)\n",
    "\n",
    "            list_nodes_Gnew = list(G_new.nodes())\n",
    "\n",
    "            length = {}\n",
    "            dis = {}\n",
    "            pre = {} \n",
    "            result = SPFA2(G_new)\n",
    "\n",
    "            if len(result) > 3:\n",
    "                break\n",
    "\n",
    "            [vv,pre,stri] = result\n",
    "            negt = Trace(pre,vv)\n",
    "            print(negt)\n",
    "\n",
    "            sumcycle = 0\n",
    "            for i in range(len(negt) - 1):\n",
    "                sumcycle += G_new[negt[i]][negt[i+1]]['tuv']\n",
    "            print(\"negative t-cycle was not fixed: \", sumcycle)\n",
    "            y_neg2 = np.copy(y_neg)\n",
    "            negt2 = copy.deepcopy(negt)\n",
    "            for i in range(len(negt)): \n",
    "                if type(negt[i]) == str:\n",
    "                    negt2[i] = list_nodes.index(negt[i])\n",
    "            for i in range(len(negt2)):\n",
    "                if negt2[i] < len(G_SBM.nodes()):\n",
    "                    if i == len(negt2) - 1:\n",
    "                        break\n",
    "                    if negt2[i+1] < len(G_SBM.nodes()):\n",
    "                        y_neg2[negt2[i]] = y_neg[negt2[i+1]]\n",
    "                    if negt2[i + 1] >= len(G_SBM.nodes()) and negt2[i+1] < len(G_SBM.nodes()) + k:\n",
    "                        y_neg2[negt2[i]] = negt2[i+1] % len(G_SBM.nodes())\n",
    "\n",
    "            y_neg = copy.deepcopy(y_neg2)\n",
    "            _,avgdistneg = compute_avg_kdistance_inertia(y_neg, k, X_dist)\n",
    "            # using closeness utility\n",
    "            #_,avgfairnessneg = compute_util_avgprop_closeness(G_SBM, list_nodes,k,y_neg)\n",
    "            # using statistical parity\n",
    "            _,avgfairnessneg = compute_fairness_linear(G_SBM, list_nodes,k,y_neg)\n",
    "            print(\"Cost when correcting a negative cycle: \", avgdistneg)\n",
    "            print(\"Fairness when correcting a negative cycle: \", avgfairnessneg)\n",
    "            print(\"compute metric for following the neg cycle: \", avgdistneg + alpha*avgfairnessneg)\n",
    "        \n",
    "\n",
    "    length = {}\n",
    "    dis = {}\n",
    "    pre = {} \n",
    "\n",
    "    # we get to this point if we managed to fix the negative cycle (might have to run the previuos loop multiple times) or didn't have one to begin with\n",
    "     \n",
    "    print(\"we're finding Mlow\")\n",
    "\n",
    "    Mfind = 1\n",
    "    G_M = create_M_graph(G_SBM,G_new, Mfind)\n",
    "    mresult = SPFA(G_M)\n",
    "    if(len(mresult) != 3):\n",
    "        Mfind = 0\n",
    "        G_M = create_M_graph(G_SBM,G_new, Mfind)\n",
    "        assert(len(SPFA(G_M)) == 3)\n",
    "    else:\n",
    "        while True:\n",
    "            G_M = create_M_graph(G_SBM,G_new, Mfind)\n",
    "            if SPFA(G_M) == 'no negative cycle detected':\n",
    "                break\n",
    "            Mfind *= 2\n",
    "\n",
    "    # at this point, we perform a binary search \n",
    "    # initialize M and the limits for the binary search\n",
    "    M = Mfind/2\n",
    "    delta = Mfind/2\n",
    "    low = Mfind/2\n",
    "    high = Mfind\n",
    "\n",
    "    # binary search to find M for which there is a cycle of length 0\n",
    "    termination_condition = 10e-12\n",
    "    mids = []\n",
    "    while np.abs(delta) > termination_condition:\n",
    "        if high > low: \n",
    "            mid = (high + low) / 2\n",
    "            mids.append(mid)\n",
    "        G_M = create_M_graph(G_SBM,G_new, mid)\n",
    "        if SPFA(G_M) == 'no negative cycle detected':\n",
    "            delta = mid - low\n",
    "            high = mid\n",
    "        else:\n",
    "            delta = high - mid\n",
    "            low = mid\n",
    "        print(delta)\n",
    "    whereinmidsweare = 0\n",
    "    for mm in reversed(mids):\n",
    "        whereinmidsweare += 1\n",
    "        G_M = create_M_graph(G_SBM,G_new, mm)\n",
    "        if len(SPFA(G_M)) == 3:\n",
    "           break\n",
    "    if whereinmidsweare == len(mids):\n",
    "        break\n",
    "    M=mm\n",
    "\n",
    "    G_M = create_M_graph(G_SBM,G_new, M)\n",
    "    [v,pre,stri]=SPFA(G_M)\n",
    "    # this is the best cycle that, if followed, will get us the next best clustering with the minimal ratio of cost loss to fairness/utility increase\n",
    "    myc = Trace(pre,v)\n",
    "    print(\"best cycle: \",myc)\n",
    "    ytest = np.copy(y)\n",
    "    \n",
    "    myc2 = copy.deepcopy(myc)\n",
    "    # we 'follow' the best cycle in order to find that next best clustering, and will compute the cost and fairness/utility as we start the loop again in the next iteration\n",
    "    for i in range(len(myc)): \n",
    "        if type(myc[i]) == str:\n",
    "            myc2[i] = list_nodes.index(myc[i])\n",
    "    for i in range(len(myc2)):\n",
    "        print(myc2[i])\n",
    "        if myc2[i] < len(G_SBM.nodes()):\n",
    "            if i == len(myc2) - 1:\n",
    "                break\n",
    "            if myc2[i+1] < len(G_SBM.nodes()):\n",
    "                #a = y[myc2[i]]\n",
    "                ytest[myc2[i]] = y[myc2[i+1]]\n",
    "            if myc2[i + 1] >= len(G_SBM.nodes()) and myc2[i+1] < len(G_SBM.nodes()) + k:\n",
    "                print(myc2[i+1])\n",
    "                ytest[myc2[i]] = myc2[i+1] % len(G_SBM.nodes())\n",
    "    y = np.copy(ytest)\n",
    "\n",
    "print(\"Fairness: \", fairness_list)\n",
    "print(\"Cost: \", cost_list)\n",
    "#filename = 'SBM_n' + str(len(list_nodes)) + '_r' + str(ratio) + '_k' + str(k) + 'closeness-test.csv'\n",
    "#filename = 'Highschool_k' + str(k) + 'statparity_test.csv'\n",
    "#f = open(filename,'w')\n",
    "#writer=csv.writer(f,lineterminator=\"\\n\")\n",
    "#writer.writerow(fairness_list)\n",
    "#writer.writerow(cost_list)\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87974aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['845', '92', '845']\n",
      "negative t-cycle was not fixed:  -0.006338780461233318\n",
      "Cost when correcting a negative cycle:  1.1911696742660702\n",
      "Fairness when correcting a negative cycle:  30.470588235294116\n",
      "[129, '222', 128, 129]\n",
      "negative t-cycle was not fixed:  -0.0007789029593255892\n",
      "Cost when correcting a negative cycle:  1.1903907713067448\n",
      "Fairness when correcting a negative cycle:  32.470588235294116\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qc/k6jgnl3532x82rw058f_4nj40002pv/T/ipykernel_9298/819209532.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mvv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstri\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mnegt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# this is an example of a loop that 'fixes' negative cycles until there are no more (until we get to the optimal cycle in the objective set)\n",
    "while True:    \n",
    "    G_new = nx.DiGraph()\n",
    "    G_new.add_nodes_from(G_SBM)\n",
    "    G_new = doubly_weighted_G(G_SBM,G_new,list_nodes,y_neg,k,X_dist)\n",
    "    list_nodes_Gnew = list(G_new.nodes())\n",
    "\n",
    "    length = {}\n",
    "    dis = {}\n",
    "    pre = {} \n",
    "    result = SPFA2(G_new)\n",
    "\n",
    "    if len(result) > 3:\n",
    "        break\n",
    "\n",
    "    [vv,pre,stri] = result\n",
    "    negt = Trace(pre,vv)\n",
    "    print(negt)\n",
    "\n",
    "    sumcycle = 0\n",
    "    for i in range(len(negt) - 1):\n",
    "        sumcycle += G_new[negt[i]][negt[i+1]]['tuv']\n",
    "    print(\"negative t-cycle was not fixed: \", sumcycle)\n",
    "    y_neg2 = np.copy(y_neg)\n",
    "    negt2 = copy.deepcopy(negt)\n",
    "    for i in range(len(negt)): \n",
    "        if type(negt[i]) == str:\n",
    "            negt2[i] = list_nodes.index(negt[i])\n",
    "    for i in range(len(negt2)):\n",
    "        if negt2[i] < len(G_SBM.nodes()):\n",
    "            if i == len(negt2) - 1:\n",
    "                break\n",
    "            if negt2[i+1] < len(G_SBM.nodes()):\n",
    "                y_neg2[negt2[i]] = y_neg[negt2[i+1]]\n",
    "            if negt2[i + 1] >= len(G_SBM.nodes()) and negt2[i+1] < len(G_SBM.nodes()) + k:\n",
    "                y_neg2[negt2[i]] = negt2[i+1] % len(G_SBM.nodes())\n",
    "\n",
    "    y_neg = copy.deepcopy(y_neg2)\n",
    "    _,avgdistneg = compute_avg_kdistance_inertia(y_neg, k, X_dist)\n",
    "    # using closeness utility\n",
    "    #_,avgfairnessneg = compute_util_avgprop_closeness(G_SBM, list_nodes,k,y_neg)\n",
    "    # using statistical parity\n",
    "    _,avgfairnessneg = compute_fairness_linear(G_SBM, list_nodes,k,y_neg)\n",
    "    print(\"Cost when correcting a negative cycle: \", avgdistneg)\n",
    "    print(\"Fairness when correcting a negative cycle: \", avgfairnessneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b920ce1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "427b11d7",
   "metadata": {},
   "source": [
    "### Re-color the clusters found by spectral clustering, one all red and one all blue, to see how the algorithm changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8d2db75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 1 1\n",
      " 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# these are the iterations that the trade-off algorithm runs; note that beyond iteration 0, the starting clustering is no longer optimal in the optimization objective (for k-means, that means inertia)\n",
    "no_of_iterations = 6\n",
    "fairness_list = []\n",
    "cost_list = []\n",
    "\n",
    "# k is the number of clusters for spectral clustering\n",
    "#k = len(sizes) # for simulated model\n",
    "k = 2 # for the real data; needs to be varied\n",
    "\n",
    "\n",
    "# computing the spectrum of the graph\n",
    "A = nx.adjacency_matrix(G_SBM)\n",
    "# computing the normalized Laplacian of the graph\n",
    "L = nx.normalized_laplacian_matrix(G_SBM)\n",
    "L.todense()\n",
    "D = np.diag(np.sum(np.array(A.todense()), axis=1))\n",
    "\n",
    "# computing the eigenvalues and eigenvectors of the normalized Laplacian\n",
    "e, v = np.linalg.eig(L.todense())\n",
    "\n",
    "# only take the first k sorted eigenvalues (can start from 0 or from 1, since first is 0 given that we have one connected component often times)\n",
    "i = [list(e).index(j) for j in sorted(list(e))[1:k+1]]\n",
    "print(i)\n",
    "\n",
    "\n",
    "U = np.array(v[:, i])\n",
    "# performing manual spectral clustering: using the first k values of the eigenspace to do k-means \n",
    "#km = KMeans(init='k-means++', n_clusters=k, max_iter=200, n_init=200, verbose=0, random_state=3425)\n",
    "km = KMeans(init='k-means++', n_clusters=k, max_iter=200, n_init=200, verbose=0)\n",
    "\n",
    "km.fit(U)\n",
    "y = km.labels_\n",
    "# distances from the k-centers\n",
    "X_dist = km.transform(U)**2\n",
    "\n",
    "# keeping a copy of the clustering assignment\n",
    "y_copy = copy.deepcopy(y)\n",
    "print(y_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd00be0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f10b4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_SBM_recolor = copy.deepcopy(G_SBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "138d0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in range(len(list_nodes)):\n",
    "    if y[u] == 0:\n",
    "        G_SBM_recolor.nodes[list_nodes[u]]['color'] = 'b'\n",
    "    else:\n",
    "        G_SBM_recolor.nodes[list_nodes[u]]['color'] = 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c937685c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_SBM_recolor.nodes[list_nodes[3]]['color'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c6e5553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_SBM.nodes[list_nodes[3]]['color'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "094990f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09987442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49179c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number:  0\n",
      "Average unfairness:  56.0\n",
      "Average cost:  0.2561903917149986\n",
      "we're finding Mlow\n",
      "1024.0\n",
      "512.0\n",
      "256.0\n",
      "128.0\n",
      "64.0\n",
      "32.0\n",
      "16.0\n",
      "8.0\n",
      "4.0\n",
      "2.0\n",
      "1.0\n",
      "0.5\n",
      "0.25\n",
      "0.125\n",
      "0.0625\n",
      "0.03125\n",
      "0.015625\n",
      "0.0078125\n",
      "0.00390625\n",
      "0.001953125\n",
      "0.0009765625\n",
      "0.00048828125\n",
      "0.000244140625\n",
      "0.0001220703125\n",
      "6.103515625e-05\n",
      "3.0517578125e-05\n",
      "1.52587890625e-05\n",
      "7.62939453125e-06\n",
      "3.814697265625e-06\n",
      "1.9073486328125e-06\n",
      "9.5367431640625e-07\n",
      "4.76837158203125e-07\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.4901161193847656e-08\n",
      "7.450580596923828e-09\n",
      "3.725290298461914e-09\n",
      "1.862645149230957e-09\n",
      "9.313225746154785e-10\n",
      "4.656612873077393e-10\n",
      "2.3283064365386963e-10\n",
      "1.1641532182693481e-10\n",
      "5.820766091346741e-11\n",
      "2.9103830456733704e-11\n",
      "1.4551915228366852e-11\n",
      "7.275957614183426e-12\n",
      "best cycle:  [129, '601', 128, 129]\n",
      "129\n",
      "37\n",
      "128\n",
      "128\n",
      "129\n",
      "Iteration number:  1\n",
      "Average unfairness:  55.2112676056338\n",
      "Average cost:  0.25682553263364405\n",
      "neg cycle, alpha is  0.002805267950425506\n",
      "['531', '232', '531']\n",
      "negative t-cycle was not fixed:  -0.0055493168\n",
      "Cost when correcting a negative cycle:  0.2613119631759144\n",
      "Fairness when correcting a negative cycle:  53.4225352112676\n",
      "Fairness:  [56.0, 55.2112676056338]\n",
      "Cost:  [0.2561903917149986, 0.25682553263364405]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for iteration in range(no_of_iterations):\n",
    "    print(\"Iteration number: \",iteration)\n",
    "    # compute the cost and fairness of this clustering\n",
    "    # using closeness utility\n",
    "    #[_,avgf] = compute_util_avgprop_closeness(G_SBM_recolor, list_nodes,k,y)\n",
    "    # using statistical parity\n",
    "    [_,avgf] = compute_fairness_linear(G_SBM_recolor, list_nodes,k,y)\n",
    "    print(\"Average unfairness: \", avgf)  \n",
    "\n",
    "    fairness_list.append(avgf)\n",
    "    [_,avgcost] = compute_avg_kdistance_inertia(y,k,X_dist)\n",
    "    print(\"Average cost: \", avgcost)\n",
    "    cost_list.append(avgcost)\n",
    "    if avgf == 0:\n",
    "        break\n",
    "    # generating G_new with double weights\n",
    "    G_new = nx.DiGraph()\n",
    "    G_new.add_nodes_from(G_SBM_recolor)\n",
    "    G_new = doubly_weighted_G(G_SBM_recolor,G_new,list_nodes,y,k,X_dist)\n",
    "    list_nodes_Gnew = list(G_new.nodes())\n",
    "\n",
    "    length = {}\n",
    "    dis = {}\n",
    "    pre = {} \n",
    "    result = SPFA2(G_new)\n",
    "    # assert that G_new does not have a negative t-cycle; if it does, then len(result) == 3 and then we 'perturb' the weights to get rid of this negative t-cycle\n",
    "    if len(result) == 3:\n",
    "        # if we are not at the initial clustering\n",
    "        if iteration > 0:\n",
    "            #my_slope = compute_slope(fairness_list[iteration-1], cost_list[iteration-1], fairness_list[iteration], cost_list[iteration])\n",
    "            #myM = -1/my_slope\n",
    "            #epsilon = myM*1e-60\n",
    "            #print(\"M and slope:\", M, myM)\n",
    "            alpha = (cost_list[iteration-1] - cost_list[iteration]) / (fairness_list[iteration] - fairness_list[iteration - 1])\n",
    "            alpha += 2e-3\n",
    "            print(\"neg cycle, alpha is \", alpha)\n",
    "            for e in G_new.edges():\n",
    "                \n",
    "                #G_new[e[0]][e[1]]['tuv'] += G_new[e[0]][e[1]]['auv']/(myM+epsilon)\n",
    "                G_new[e[0]][e[1]]['tuv'] += alpha* G_new[e[0]][e[1]]['auv']\n",
    "                G_new[e[0]][e[1]]['tuv'] = round(G_new[e[0]][e[1]]['tuv'],10)\n",
    "        # if we are actually at the initial clustering (SC is not the optimal one); can ignore\n",
    "        #if iteration == 0:\n",
    "            #my_slope = compute_slope(0.2, 0, fairness_list[iteration], cost_list[iteration])\n",
    "            #myM = -1/my_slope\n",
    "            #epsilon = myM*1e-60\n",
    "            #print(\"M and slope:\", M, myM)\n",
    "            #for e in G_new.edges():\n",
    "            #    G_new[e[0]][e[1]]['tuv'] += G_new[e[0]][e[1]]['auv']/(myM+epsilon)\n",
    "            #    G_new[e[0]][e[1]]['tuv'] = round(G_new[e[0]][e[1]]['tuv'],10)\n",
    "                \n",
    "    length = {}\n",
    "    dis = {}\n",
    "    pre = {} \n",
    "    newresult = SPFA2(G_new) \n",
    "\n",
    "    # assert again that G_new does not have a negative t-cycle; if it does, then len(result) == 3 and then we see what clustering we get if we 'fix' the negative t-cycle\n",
    "    if len(newresult) == 3:\n",
    "        [vv,pre,stri] = newresult\n",
    "        negt = Trace(pre,vv)\n",
    "        print(negt)\n",
    "        sumcycle = 0\n",
    "        for i in range(len(negt) - 1):\n",
    "            sumcycle += G_new[negt[i]][negt[i+1]]['tuv']\n",
    "        print(\"negative t-cycle was not fixed: \", sumcycle)\n",
    "        y_neg = np.copy(y)\n",
    "        negt2 = copy.deepcopy(negt)\n",
    "        for i in range(len(negt)): \n",
    "            if type(negt[i]) == str:\n",
    "                negt2[i] = list_nodes.index(negt[i])\n",
    "        for i in range(len(negt2)):\n",
    "            if negt2[i] < len(G_SBM_recolor.nodes()):\n",
    "                if i == len(negt2) - 1:\n",
    "                    break\n",
    "                if negt2[i+1] < len(G_SBM_recolor.nodes()):\n",
    "                    y_neg[negt2[i]] = y[negt2[i+1]]\n",
    "                if negt2[i + 1] >= len(G_SBM_recolor.nodes()) and negt2[i+1] < len(G_SBM_recolor.nodes()) + k:\n",
    "                    y_neg[negt2[i]] = negt2[i+1] % len(G_SBM_recolor.nodes())\n",
    "        _,avgdistneg = compute_avg_kdistance_inertia(y_neg, k, X_dist)\n",
    "        # using closeness utility\n",
    "        #_,avgfairnessneg = compute_util_avgprop_closeness(G_SBM, list_nodes,k,y_neg)\n",
    "        # using statistical parity\n",
    "        _,avgfairnessneg = compute_fairness_linear(G_SBM_recolor, list_nodes,k,y_neg)\n",
    "        print(\"Cost when correcting a negative cycle: \", avgdistneg)\n",
    "        print(\"Fairness when correcting a negative cycle: \", avgfairnessneg)\n",
    "\n",
    "        break\n",
    "\n",
    "    length = {}\n",
    "    dis = {}\n",
    "    pre = {} \n",
    "\n",
    "    # we get to this point if we managed to fix the negative cycle (might have to run the previuos loop multiple times) or didn't have one to begin with\n",
    "     \n",
    "    print(\"we're finding Mlow\")\n",
    "\n",
    "    Mfind = 1\n",
    "    G_M = create_M_graph(G_SBM_recolor,G_new, Mfind)\n",
    "    mresult = SPFA(G_M)\n",
    "    if(len(mresult) != 3):\n",
    "        Mfind = 0\n",
    "        G_M = create_M_graph(G_SBM_recolor,G_new, Mfind)\n",
    "        assert(len(SPFA(G_M)) == 3)\n",
    "    else:\n",
    "        while True:\n",
    "            G_M = create_M_graph(G_SBM_recolor,G_new, Mfind)\n",
    "            if SPFA(G_M) == 'no negative cycle detected':\n",
    "                break\n",
    "            Mfind *= 2\n",
    "\n",
    "    # at this point, we perform a binary search \n",
    "    # initialize M and the limits for the binary search\n",
    "    M = Mfind/2\n",
    "    delta = Mfind/2\n",
    "    low = Mfind/2\n",
    "    high = Mfind\n",
    "\n",
    "    # binary search to find M for which there is a cycle of length 0\n",
    "    termination_condition = 10e-12\n",
    "    mids = []\n",
    "    while np.abs(delta) > termination_condition:\n",
    "        if high > low: \n",
    "            mid = (high + low) / 2\n",
    "            mids.append(mid)\n",
    "        G_M = create_M_graph(G_SBM_recolor,G_new, mid)\n",
    "        if SPFA(G_M) == 'no negative cycle detected':\n",
    "            delta = mid - low\n",
    "            high = mid\n",
    "        else:\n",
    "            delta = high - mid\n",
    "            low = mid\n",
    "        print(delta)\n",
    "    whereinmidsweare = 0\n",
    "    for mm in reversed(mids):\n",
    "        whereinmidsweare += 1\n",
    "        G_M = create_M_graph(G_SBM_recolor,G_new, mm)\n",
    "        if len(SPFA(G_M)) == 3:\n",
    "           break\n",
    "    if whereinmidsweare == len(mids):\n",
    "        break\n",
    "    M=mm\n",
    "\n",
    "    G_M = create_M_graph(G_SBM_recolor,G_new, M)\n",
    "    [v,pre,stri]=SPFA(G_M)\n",
    "    # this is the best cycle that, if followed, will get us the next best clustering with the minimal ratio of cost loss to fairness/utility increase\n",
    "    myc = Trace(pre,v)\n",
    "    print(\"best cycle: \",myc)\n",
    "    ytest = np.copy(y)\n",
    "    \n",
    "    myc2 = copy.deepcopy(myc)\n",
    "    # we 'follow' the best cycle in order to find that next best clustering, and will compute the cost and fairness/utility as we start the loop again in the next iteration\n",
    "    for i in range(len(myc)): \n",
    "        if type(myc[i]) == str:\n",
    "            myc2[i] = list_nodes.index(myc[i])\n",
    "    for i in range(len(myc2)):\n",
    "        print(myc2[i])\n",
    "        if myc2[i] < len(G_SBM_recolor.nodes()):\n",
    "            if i == len(myc2) - 1:\n",
    "                break\n",
    "            if myc2[i+1] < len(G_SBM_recolor.nodes()):\n",
    "                #a = y[myc2[i]]\n",
    "                ytest[myc2[i]] = y[myc2[i+1]]\n",
    "            if myc2[i + 1] >= len(G_SBM_recolor.nodes()) and myc2[i+1] < len(G_SBM_recolor.nodes()) + k:\n",
    "                print(myc2[i+1])\n",
    "                ytest[myc2[i]] = myc2[i+1] % len(G_SBM_recolor.nodes())\n",
    "    y = np.copy(ytest)\n",
    "\n",
    "print(\"Fairness: \", fairness_list)\n",
    "print(\"Cost: \", cost_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff0e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cc5e429",
   "metadata": {},
   "source": [
    "### (Re-)compute centroids to see how much they shift  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d276d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroids(G, list_nodes_G, no_clusters, cluster_assignment,myU):\n",
    "    list_centroids = []\n",
    "    for kk in range(no_clusters):\n",
    "        list_centroids.append(myU[np.where(cluster_assignment==kk),:][0].mean(axis=0))\n",
    "    return list_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81849688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09065151,  0.07576987])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df1ddc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums=np.sqrt(np.sum(np.square(U),axis=1)).reshape(-1,1)\n",
    "T=U/sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d459bbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09065151,  0.07576987],\n",
       "       [-0.07839108,  0.07176045],\n",
       "       [-0.07641219,  0.07416726],\n",
       "       [-0.10771685,  0.0896779 ],\n",
       "       [-0.07486025,  0.06654638],\n",
       "       [-0.07802022,  0.07651889],\n",
       "       [-0.08792328,  0.07935799],\n",
       "       [-0.08161343,  0.0491366 ],\n",
       "       [-0.10430417,  0.0330627 ],\n",
       "       [-0.10222715,  0.05091032],\n",
       "       [-0.12728321,  0.04757702],\n",
       "       [-0.05925706,  0.05127619],\n",
       "       [-0.06374782,  0.03651916],\n",
       "       [ 0.00552563, -0.01437407],\n",
       "       [ 0.0396774 , -0.02011021],\n",
       "       [ 0.03651708, -0.01963857],\n",
       "       [-0.06801525,  0.03785513],\n",
       "       [-0.10420171, -0.00185313],\n",
       "       [-0.10975343,  0.00076009],\n",
       "       [-0.10087906,  0.00645671],\n",
       "       [-0.10499603,  0.00796095],\n",
       "       [-0.02717378,  0.04687581],\n",
       "       [-0.05815078,  0.02445837],\n",
       "       [ 0.10740208, -0.03990279],\n",
       "       [ 0.11615944, -0.04184782],\n",
       "       [ 0.17078796, -0.0600471 ],\n",
       "       [ 0.1648699 , -0.06051966],\n",
       "       [ 0.09418435, -0.03525669],\n",
       "       [ 0.14483175, -0.0564678 ],\n",
       "       [ 0.09052749, -0.0326898 ],\n",
       "       [ 0.10068129, -0.03644388],\n",
       "       [ 0.12421751, -0.0447121 ],\n",
       "       [-0.01861273,  0.07351064],\n",
       "       [-0.02171597,  0.05711814],\n",
       "       [-0.01861273,  0.07351064],\n",
       "       [-0.0061464 ,  0.06187508],\n",
       "       [-0.01263422,  0.06835131],\n",
       "       [ 0.00836331,  0.06909211],\n",
       "       [-0.0061464 ,  0.06187508],\n",
       "       [-0.07833331,  0.03934346],\n",
       "       [-0.11655672,  0.08655605],\n",
       "       [-0.07991718,  0.05224816],\n",
       "       [-0.0689742 ,  0.0395845 ],\n",
       "       [-0.07683552,  0.04526907],\n",
       "       [-0.07948293,  0.06976775],\n",
       "       [-0.08077396,  0.06403396],\n",
       "       [-0.07758661,  0.07582194],\n",
       "       [ 0.05390307, -0.02021801],\n",
       "       [ 0.13995344, -0.04422397],\n",
       "       [-0.10082524, -0.04147274],\n",
       "       [-0.12999854, -0.05350534],\n",
       "       [-0.1215413 , -0.05624212],\n",
       "       [-0.11641763, -0.04283992],\n",
       "       [-0.13676924, -0.05503846],\n",
       "       [-0.12461994, -0.04527827],\n",
       "       [-0.06007862,  0.03904919],\n",
       "       [-0.05742818,  0.05406434],\n",
       "       [ 0.02139127,  0.04329045],\n",
       "       [-0.00141452,  0.03852465],\n",
       "       [ 0.00317934,  0.03889363],\n",
       "       [ 0.05833525,  0.03478606],\n",
       "       [ 0.01961026,  0.04917065],\n",
       "       [-0.01472321,  0.04313132],\n",
       "       [-0.00431396,  0.03674997],\n",
       "       [-0.01431587,  0.04985695],\n",
       "       [-0.00402533,  0.06509784],\n",
       "       [ 0.12524326, -0.03445456],\n",
       "       [ 0.05061276,  0.0104979 ],\n",
       "       [ 0.0503237 ,  0.04261556],\n",
       "       [-0.12454011, -0.04676564],\n",
       "       [-0.13171116, -0.10384044],\n",
       "       [-0.05737001, -0.04625249],\n",
       "       [-0.08547364,  0.03787163],\n",
       "       [-0.08206618,  0.07069627],\n",
       "       [-0.02968904,  0.0357907 ],\n",
       "       [-0.06943536,  0.06204909],\n",
       "       [-0.0093334 ,  0.04110865],\n",
       "       [-0.11335963, -0.24353392],\n",
       "       [ 0.05694412, -0.05064822],\n",
       "       [ 0.13252167, -0.04787861],\n",
       "       [ 0.12069642, -0.03876722],\n",
       "       [ 0.14585152, -0.05089827],\n",
       "       [ 0.10678768, -0.03629229],\n",
       "       [-0.00748269,  0.04724889],\n",
       "       [-0.01172094,  0.07569295],\n",
       "       [-0.08152888,  0.01580447],\n",
       "       [ 0.07646656, -0.02925322],\n",
       "       [ 0.12897244, -0.04618903],\n",
       "       [ 0.13227963, -0.04164913],\n",
       "       [ 0.12298367, -0.04394804],\n",
       "       [ 0.13140376, -0.0461062 ],\n",
       "       [ 0.11404047, -0.03165262],\n",
       "       [ 0.0851813 , -0.06104726],\n",
       "       [ 0.08939928, -0.03356858],\n",
       "       [ 0.13080886, -0.04686566],\n",
       "       [ 0.03938505, -0.02884186],\n",
       "       [ 0.0612398 , -0.02300114],\n",
       "       [-0.02948467,  0.0305269 ],\n",
       "       [-0.04033101,  0.04086539],\n",
       "       [ 0.09280901, -0.0325122 ],\n",
       "       [ 0.02719114,  0.05406978],\n",
       "       [ 0.02057574,  0.04280642],\n",
       "       [ 0.1477815 , -0.05359924],\n",
       "       [ 0.03879397,  0.02875757],\n",
       "       [ 0.03879397,  0.02875757],\n",
       "       [ 0.10011678, -0.03135842],\n",
       "       [-0.01092471, -0.04545765],\n",
       "       [-0.02558178, -0.03688085],\n",
       "       [ 0.02033711,  0.01302687],\n",
       "       [ 0.09325862, -0.02607509],\n",
       "       [ 0.12494124, -0.04571893],\n",
       "       [ 0.06265042, -0.05023839],\n",
       "       [-0.18234754, -0.49668835],\n",
       "       [-0.15932996, -0.45405417],\n",
       "       [-0.15932996, -0.45405417],\n",
       "       [ 0.14740517, -0.05256493],\n",
       "       [-0.00841201,  0.01947216],\n",
       "       [ 0.00578164,  0.01415331],\n",
       "       [ 0.02057574,  0.04280642],\n",
       "       [ 0.10011678, -0.03135842],\n",
       "       [ 0.10011678, -0.03135842],\n",
       "       [ 0.05429303, -0.04206144],\n",
       "       [ 0.05899145, -0.01482505],\n",
       "       [ 0.06167078, -0.02043309],\n",
       "       [ 0.0914017 , -0.03176767],\n",
       "       [ 0.05647248, -0.02053497],\n",
       "       [ 0.05647248, -0.02053497]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "81d8164f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  16,  17,  18,  19,  20,  21,  22,  32,  33,  34,  35,  36,\n",
       "         37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  61,  62,  63,  64,  65,\n",
       "         68,  69,  70,  71,  72,  73,  74,  75,  76,  83,  84,  85,  97,\n",
       "         98, 100, 101, 103, 104, 106, 107, 108, 116, 117, 118]),)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "05e6fd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09065151,  0.07576987],\n",
       "       [-0.07839108,  0.07176045],\n",
       "       [-0.07641219,  0.07416726],\n",
       "       [-0.10771685,  0.0896779 ],\n",
       "       [-0.07486025,  0.06654638],\n",
       "       [-0.07802022,  0.07651889],\n",
       "       [-0.08792328,  0.07935799],\n",
       "       [-0.08161343,  0.0491366 ],\n",
       "       [-0.10430417,  0.0330627 ],\n",
       "       [-0.10222715,  0.05091032],\n",
       "       [-0.12728321,  0.04757702],\n",
       "       [-0.05925706,  0.05127619],\n",
       "       [-0.06374782,  0.03651916],\n",
       "       [ 0.00552563, -0.01437407],\n",
       "       [-0.06801525,  0.03785513],\n",
       "       [-0.10420171, -0.00185313],\n",
       "       [-0.10975343,  0.00076009],\n",
       "       [-0.10087906,  0.00645671],\n",
       "       [-0.10499603,  0.00796095],\n",
       "       [-0.02717378,  0.04687581],\n",
       "       [-0.05815078,  0.02445837],\n",
       "       [-0.01861273,  0.07351064],\n",
       "       [-0.02171597,  0.05711814],\n",
       "       [-0.01861273,  0.07351064],\n",
       "       [-0.0061464 ,  0.06187508],\n",
       "       [-0.01263422,  0.06835131],\n",
       "       [ 0.00836331,  0.06909211],\n",
       "       [-0.0061464 ,  0.06187508],\n",
       "       [-0.07833331,  0.03934346],\n",
       "       [-0.11655672,  0.08655605],\n",
       "       [-0.07991718,  0.05224816],\n",
       "       [-0.0689742 ,  0.0395845 ],\n",
       "       [-0.07683552,  0.04526907],\n",
       "       [-0.07948293,  0.06976775],\n",
       "       [-0.08077396,  0.06403396],\n",
       "       [-0.07758661,  0.07582194],\n",
       "       [-0.10082524, -0.04147274],\n",
       "       [-0.12999854, -0.05350534],\n",
       "       [-0.1215413 , -0.05624212],\n",
       "       [-0.11641763, -0.04283992],\n",
       "       [-0.13676924, -0.05503846],\n",
       "       [-0.12461994, -0.04527827],\n",
       "       [-0.06007862,  0.03904919],\n",
       "       [-0.05742818,  0.05406434],\n",
       "       [ 0.02139127,  0.04329045],\n",
       "       [-0.00141452,  0.03852465],\n",
       "       [ 0.00317934,  0.03889363],\n",
       "       [ 0.01961026,  0.04917065],\n",
       "       [-0.01472321,  0.04313132],\n",
       "       [-0.00431396,  0.03674997],\n",
       "       [-0.01431587,  0.04985695],\n",
       "       [-0.00402533,  0.06509784],\n",
       "       [ 0.0503237 ,  0.04261556],\n",
       "       [-0.12454011, -0.04676564],\n",
       "       [-0.13171116, -0.10384044],\n",
       "       [-0.05737001, -0.04625249],\n",
       "       [-0.08547364,  0.03787163],\n",
       "       [-0.08206618,  0.07069627],\n",
       "       [-0.02968904,  0.0357907 ],\n",
       "       [-0.06943536,  0.06204909],\n",
       "       [-0.0093334 ,  0.04110865],\n",
       "       [-0.00748269,  0.04724889],\n",
       "       [-0.01172094,  0.07569295],\n",
       "       [-0.08152888,  0.01580447],\n",
       "       [-0.02948467,  0.0305269 ],\n",
       "       [-0.04033101,  0.04086539],\n",
       "       [ 0.02719114,  0.05406978],\n",
       "       [ 0.02057574,  0.04280642],\n",
       "       [ 0.03879397,  0.02875757],\n",
       "       [ 0.03879397,  0.02875757],\n",
       "       [-0.01092471, -0.04545765],\n",
       "       [-0.02558178, -0.03688085],\n",
       "       [ 0.02033711,  0.01302687],\n",
       "       [-0.00841201,  0.01947216],\n",
       "       [ 0.00578164,  0.01415331],\n",
       "       [ 0.02057574,  0.04280642]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[np.where(y==0),:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0aacacbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0507766 ,  0.03258887])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[np.where(y==0),:][0].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7935f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
